{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition - Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Train a Conditional Random Field (CRF) model to perform Named Entity Recognition (NER) on the Ontonotes V5.0 dataset. The Kaggle competition page can be [found here](https://www.kaggle.com/c/colx-563-lab-assignment-1/overview).\n",
    "\n",
    "## Results\n",
    "\n",
    "* Private Leaderboard: **1st place** (micro F1 score: 0.96819)\n",
    "* Public Leaderboard: **2nd place** (micro F1 score: 0.96838)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import names, gazetteers, stopwords\n",
    "from nltk import pos_tag\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score, flat_classification_report\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontonotes_path = \"data/ner_kaggle_competition/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ['train/' + filename for filename in os.listdir(ontonotes_path + 'train')]\n",
    "dev_data = ['dev/' + filename for filename in os.listdir(ontonotes_path + 'dev')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train/wsj_2164.name',\n",
       " 'train/wsj_0509.name',\n",
       " 'train/abc_0025.name',\n",
       " 'train/wsj_2021.name',\n",
       " 'train/mnb_0007.name',\n",
       " 'train/wsj_1877.name',\n",
       " 'train/cnn_0331.name',\n",
       " 'train/wsj_0765.name',\n",
       " 'train/wsj_0335.name',\n",
       " 'train/wsj_1174.name']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block converts data from the `.name` files format to standard IOB/BIO tags appropriate for conducting Named Entity Recognition (NER).\n",
    "\n",
    "The `.name` files contain sentences with XML tags which indicate specific named entities. For instance, in the following example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " < ENAMEX TYPE=\"GPE\" > Hong Kong < /ENAMEX >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tag for 'Hong' is *B-GPE* and 'Kong' is *I-GPE* (GPE stands for Geopolitical Entity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = 'While <ENAMEX TYPE=\"PERSON\">Galloway</ENAMEX> \\'s <ENAMEX TYPE=\"ORG\" S_OFF=\"4\">pro-Wal-Mart</ENAMEX> film introduces us to grateful employees /-'\n",
    "sentence2 = '<ENAMEX TYPE=\"GPE\">Moscow</ENAMEX> , overcast changing to moderate snow , <ENAMEX TYPE=\"QUANTITY\">2 degrees below zero</ENAMEX> to <ENAMEX TYPE=\"QUANTITY\">1 degree</ENAMEX> .'\n",
    "soup = BeautifulSoup(sentence1, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "def sentence2iob(sentence):\n",
    "    '''Input sentence is a string from the Ontonotes corpus, with xml tags indicating named entities\n",
    "    output is a list of tokens and a list of NER IOB-tags corresponding to those tokens'''\n",
    "    soup = BeautifulSoup(sentence, \"html.parser\")\n",
    "    curr_tokens = []\n",
    "    curr_tags = []\n",
    "    for child in soup:\n",
    "        if child.name == \"enamex\" and not isinstance(child, bs4.element.NavigableString):\n",
    "            ner_toks = child.get_text().split()\n",
    "            for i, tok in enumerate(ner_toks):\n",
    "                curr_tokens.append(tok)\n",
    "                if i == 0:\n",
    "                    curr_tags.append(\"B-\" + child.get(\"type\"))\n",
    "                else:\n",
    "                    curr_tags.append(\"I-\" + child.get(\"type\"))\n",
    "        else:\n",
    "            for tok in child.split():\n",
    "                curr_tags.append(\"O\")\n",
    "                curr_tokens.append(tok)\n",
    "    \n",
    "    return curr_tokens, curr_tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-majalla.com/ListNews.a...=1175-AMP-MenuID=8\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://whymsi.com/awing\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://msi-team.com/awing\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://z12.zupload.com/download.php?file=getfile-AMP-filepath=6894\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.furk.net/newsadam.avi.html\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.pukmedia.com/arabicnews/6-1/news33.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://yooha.meepzorp.com/out-spot/index_files/out-spot.jpg\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://home.hamptonroads.com/stories/story.cfm?story=105522-AMP-ran=48577\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/22112006/roods42.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/29112006/rood55.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/06122006/rood2.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/13122006/rood43.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/20122006/rood43.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/10012007/rood57.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/17012007/rood40.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/24012007/rood2.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.analystnewspaper.com/ameu_scam_feb21.html\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.waynemadsenreport.com/\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.globalpolicy.org/intljustice/wanted/2005/1212ties.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://dave.typepad.com/dave/2004/06/janet_jacksons_.html\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.egotastic.com/entertainment/celebrities/janet-jackson/janet-jackson-is-too-fat-to-sing\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.msnbc.msn.com/id/11800917/\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://news.bbc.co.uk/1/hi/programmes/panorama/live_forums/2124808.stm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://stargods.org/MasonicMichaelJackson.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://alsaha2.fares.net/sahat?128@247.n9fpcUVKH9b.0@.3ba9b6f7\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.almokhtsar.com/html/news/1413/2/65370.php\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://alsaha.fares.net/sahat?128@96.GdrOcqF3AIR.21@.3ba9a044\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.islamtoday.net/pen/show_articles_content.cfm?id=64-AMP-catid=195-AMP-artid=8476\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "check_sentence = 'While <ENAMEX TYPE=\"PERSON\">Galloway</ENAMEX> \\'s <ENAMEX TYPE=\"ORG\" S_OFF=\"4\">pro-Wal-Mart</ENAMEX> film introduces us to grateful employees /-'\n",
    "curr_tokens, curr_tags = sentence2iob(check_sentence)\n",
    "assert curr_tags == ['O', 'B-PERSON', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "\n",
    "check_sentence = '<ENAMEX TYPE=\"GPE\">Moscow</ENAMEX> , overcast changing to moderate snow , <ENAMEX TYPE=\"QUANTITY\">2 degrees below zero</ENAMEX> to <ENAMEX TYPE=\"QUANTITY\">1 degree</ENAMEX> .'\n",
    "curr_tokens, curr_tags = sentence2iob(check_sentence)\n",
    "assert curr_tags == ['B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QUANTITY', 'I-QUANTITY', 'I-QUANTITY', 'I-QUANTITY', 'O', 'B-QUANTITY', 'I-QUANTITY', 'O']\n",
    "\n",
    "# If tests passed, then create tokens and tags\n",
    "token_count = 0\n",
    "for filename in train_data:\n",
    "    with open(ontonotes_path + filename, encoding=\"utf-8\") as f:\n",
    "        f.readline()\n",
    "        for sentence in f:\n",
    "            curr_tokens, curr_tags = sentence2iob(sentence)\n",
    "            token_count += len(curr_tokens)\n",
    "            assert \"\" not in curr_tokens # checking for empty strings\n",
    "\n",
    "assert token_count == 1096878\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "The following function `word2features` creates a set of features which are informative and relevant for the training procedure. Some of the engineered features include:\n",
    "\n",
    "- Features which looks at neighbouring words.\n",
    "- Features which looks at word morphology.\n",
    "- Features which considers the \"shape\" of word.\n",
    "- Features which include POS tags.\n",
    "- Gazetteer features using the `nltk` Gazetteer corpus.\n",
    "- Name features using the `nltk` Names corpus.\n",
    "- Stop words features using the `nltk` StopWords corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazetteer_words = set(gazetteers.words())\n",
    "names_words = set(names.words())\n",
    "stop_words = set(stopwords.words())\n",
    "\n",
    "def word2features(sentence, idx):\n",
    "    \"\"\"Engineers informative features for the NER model training.\"\"\"\n",
    "    pos_tags = pos_tag(sentence)\n",
    "    word_features = {}\n",
    "    # token\n",
    "    word_features[\"word\"] = sentence[idx]\n",
    "    # POS tags\n",
    "    word_features[\"pos_tag_full\"] = pos_tags[idx][1]\n",
    "    word_features[\"pos_tag_short\"] = pos_tags[idx][1][:2]\n",
    "    # lower case\n",
    "    word_features[\"word_lowercase\"] = sentence[idx].lower()\n",
    "    # first word upper case (boolean)\n",
    "    if idx == 0:\n",
    "        word_features[\"word_uppercase\"] = True\n",
    "    # upper case (boolean)\n",
    "    if sentence[idx].isupper():\n",
    "        word_features[\"word_alluppercase\"] = True\n",
    "    # tile case (boolean)\n",
    "    if not sentence[idx].isupper() and not sentence[idx].islower() and idx != 0:\n",
    "        word_features[\"word_tilecase\"] = True\n",
    "    else:\n",
    "        word_features[\"word_tilecase\"] = False\n",
    "    # digit case (boolean)\n",
    "    word_features[\"word_isdigit\"] = sentence[idx].isdigit()\n",
    "    # all alphabet case (boolean)\n",
    "    word_features[\"word_isalpha\"] = sentence[idx].isalpha()\n",
    "    # title case (boolean)\n",
    "    word_features[\"word_istitle\"] = sentence[idx].istitle()\n",
    "    # space case (boolean)\n",
    "    word_features[\"word_isspace\"] = sentence[idx].isspace()\n",
    "    # word morphology - 3 chars\n",
    "    if len(sentence[idx]) > 3:\n",
    "        word_features[\"word_init_3chars\"] = sentence[idx][:3]\n",
    "        word_features[\"word_end_3chars\"] = sentence[idx][-3:]\n",
    "    # word morphology - 2 chars\n",
    "    if len(sentence[idx]) > 2:\n",
    "        word_features[\"word_init_2chars\"] = sentence[idx][:2]\n",
    "        word_features[\"word_end_2chars\"] = sentence[idx][-2:]\n",
    "    # neighbours\n",
    "    if idx > 0:\n",
    "        word_features[\"word_left_neighbour\"] = sentence[idx-1]\n",
    "        word_features[\"pos_tag_full_left\"] = pos_tags[idx-1][1]\n",
    "        word_features[\"pos_tag_short_left\"] = pos_tags[idx-1][1][:2]\n",
    "    if idx < len(sentence) - 1:\n",
    "        word_features[\"word_right_neighbour\"] = sentence[idx+1]\n",
    "        word_features[\"pos_tag_full_right\"] = pos_tags[idx+1][1]\n",
    "        word_features[\"pos_tag_short_right\"] = pos_tags[idx+1][1][:2]\n",
    "    if idx > 1:\n",
    "        word_features[\"word_left_left_neighbour\"] = sentence[idx-2]\n",
    "        word_features[\"pos_tag_full_left_left\"] = pos_tags[idx-2][1]\n",
    "        word_features[\"pos_tag_short_left_left\"] = pos_tags[idx-2][1][:2]\n",
    "    if idx < len(sentence) - 2:\n",
    "        word_features[\"word_right_right_neighbour\"] = sentence[idx+2]\n",
    "        word_features[\"pos_tag_full_right_right\"] = pos_tags[idx+2][1]\n",
    "        word_features[\"pos_tag_short_right_right\"] = pos_tags[idx+2][1][:2]\n",
    "    # gazetteer\n",
    "    if sentence[idx] in gazetteer_words:\n",
    "        word_features[\"gazetteers\"] = sentence[idx]\n",
    "    # names\n",
    "    if sentence[idx] in names_words:\n",
    "        word_features[\"names\"] = sentence[idx] \n",
    "    # stopwords\n",
    "    if sentence[idx] in stop_words:\n",
    "        word_features[\"stopwords\"] = sentence[idx]\n",
    "    \n",
    "    return word_features\n",
    "    \n",
    "def sentence2features(sentence):\n",
    "    \"\"\"Takes a sentence, iterates over its words, and creates a list of engineered features.\"\"\"\n",
    "    return [word2features(sentence, idx) for idx in range(len(sentence))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block prepares the feature dictionaries required to train the CRF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ner_feature_dicts(ner_files):\n",
    "    \"\"\"ner_files is a list of Ontonotes files with NER annotations. Returns feature dictionaries and \n",
    "    IOB tags for each token in the entire dataset, adpated for a CRF model.\"\"\"\n",
    "    train_dicts = []\n",
    "    train_tags = []\n",
    "    for filename in ner_files:\n",
    "        with open(ontonotes_path + filename, encoding=\"utf-8\") as f:\n",
    "            f.readline()\n",
    "            for sentence in f:\n",
    "                curr_tokens, curr_tags = sentence2iob(sentence)\n",
    "                if curr_tokens:\n",
    "                    train_dicts.extend(sentence2features(curr_tokens))\n",
    "                    train_tags.extend(curr_tags)\n",
    "                    \n",
    "    assert(len(train_dicts)) == 1096878  # checks correct length\n",
    "    \n",
    "    return train_dicts, train_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-majalla.com/ListNews.a...=1175-AMP-MenuID=8\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://whymsi.com/awing\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://msi-team.com/awing\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://z12.zupload.com/download.php?file=getfile-AMP-filepath=6894\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.furk.net/newsadam.avi.html\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.pukmedia.com/arabicnews/6-1/news33.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://yooha.meepzorp.com/out-spot/index_files/out-spot.jpg\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://home.hamptonroads.com/stories/story.cfm?story=105522-AMP-ran=48577\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/22112006/roods42.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/29112006/rood55.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/06122006/rood2.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/13122006/rood43.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/20122006/rood43.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/10012007/rood57.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/17012007/rood40.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.al-jazirah.com.sa/cars/24012007/rood2.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.analystnewspaper.com/ameu_scam_feb21.html\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.waynemadsenreport.com/\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.globalpolicy.org/intljustice/wanted/2005/1212ties.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://dave.typepad.com/dave/2004/06/janet_jacksons_.html\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.egotastic.com/entertainment/celebrities/janet-jackson/janet-jackson-is-too-fat-to-sing\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.msnbc.msn.com/id/11800917/\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://news.bbc.co.uk/1/hi/programmes/panorama/live_forums/2124808.stm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://stargods.org/MasonicMichaelJackson.htm\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://alsaha2.fares.net/sahat?128@247.n9fpcUVKH9b.0@.3ba9b6f7\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.almokhtsar.com/html/news/1413/2/65370.php\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://alsaha.fares.net/sahat?128@96.GdrOcqF3AIR.21@.3ba9a044\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.islamtoday.net/pen/show_articles_content.cfm?id=64-AMP-catid=195-AMP-artid=8476\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dicts, train_tags = prepare_ner_feature_dicts(train_data)\n",
    "dev_dicts, dev_tags = prepare_ner_feature_dicts(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/sklearn_crfsuite/estimator.py\", line 307, in fit\n",
      "    trainer = self._get_trainer()\n",
      "  File \"/Users/JJR/opt/miniconda3/envs/573/lib/python3.8/site-packages/sklearn_crfsuite/estimator.py\", line 530, in _get_trainer\n",
      "    return trainer_cls(\n",
      "  File \"pycrfsuite/_pycrfsuite.pyx\", line 260, in pycrfsuite._pycrfsuite.BaseTrainer.__init__\n",
      "  File \"pycrfsuite/_pycrfsuite.pyx\", line 390, in pycrfsuite._pycrfsuite.BaseTrainer.set_params\n",
      "  File \"pycrfsuite/_pycrfsuite.pyx\", line 421, in pycrfsuite._pycrfsuite.BaseTrainer.set\n",
      "ValueError: Parameter not found: c1 = 0.4573919215958079\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 112.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=CRF(keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'algorithm': ['lbfgs', 'l2sgd'],\n",
       "                                        'all_possible_states': [True, False],\n",
       "                                        'all_possible_transitions': [True,\n",
       "                                                                     False],\n",
       "                                        'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fec3a76eeb0>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fec3a76e3a0>,\n",
       "                                        'min_freq': [0, 10, 25, 20, 100]},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "params = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "    'min_freq': [0, 10, 25, 20, 100],\n",
    "    'algorithm': ['lbfgs', 'l2sgd'],\n",
    "    'all_possible_states': [True, False],\n",
    "    'all_possible_transitions': [True, False]\n",
    "    \n",
    "}\n",
    "\n",
    "crf = CRF(max_iterations=100)\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(flat_f1_score, average='weighted')\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, \n",
    "                        params,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_iter=5,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(train_dicts, train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'lbfgs', 'all_possible_states': True, 'all_possible_transitions': True, 'c1': 0.3584489507233674, 'c2': 0.11652449959538214, 'min_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 55468/55468 [01:14<00:00, 739.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 1\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 9810624\n",
      "Seconds required: 360.361\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.358449\n",
      "c2: 0.116524\n",
      "num_memories: 6\n",
      "max_iterations: 900\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=17.10 loss=2551961.91 active=1826650 feature_norm=1.00\n",
      "Iter 2   time=17.61 loss=1835232.23 active=1774130 feature_norm=5.98\n",
      "Iter 3   time=6.21  loss=1483518.10 active=1251247 feature_norm=5.13\n",
      "Iter 4   time=35.15 loss=840770.63 active=927167 feature_norm=3.82\n",
      "Iter 5   time=17.76 loss=773395.51 active=877555 feature_norm=3.90\n",
      "Iter 6   time=6.29  loss=694636.59 active=912348 feature_norm=4.82\n",
      "Iter 7   time=6.30  loss=620411.38 active=880450 feature_norm=6.25\n",
      "Iter 8   time=6.26  loss=522743.32 active=758688 feature_norm=9.10\n",
      "Iter 9   time=6.23  loss=445575.92 active=736237 feature_norm=10.84\n",
      "Iter 10  time=6.32  loss=401445.46 active=725705 feature_norm=12.20\n",
      "Iter 11  time=6.23  loss=363563.33 active=698647 feature_norm=14.03\n",
      "Iter 12  time=6.49  loss=333029.69 active=683913 feature_norm=15.39\n",
      "Iter 13  time=6.29  loss=304194.45 active=649383 feature_norm=17.10\n",
      "Iter 14  time=6.24  loss=265421.23 active=617064 feature_norm=19.36\n",
      "Iter 15  time=6.23  loss=236836.73 active=585549 feature_norm=22.88\n",
      "Iter 16  time=6.23  loss=219554.25 active=585811 feature_norm=24.70\n",
      "Iter 17  time=6.25  loss=197641.69 active=558363 feature_norm=29.16\n",
      "Iter 18  time=6.28  loss=178501.74 active=540242 feature_norm=35.78\n",
      "Iter 19  time=6.24  loss=160423.02 active=545676 feature_norm=38.85\n",
      "Iter 20  time=6.25  loss=147462.01 active=533634 feature_norm=43.32\n",
      "Iter 21  time=6.24  loss=133032.76 active=517384 feature_norm=50.31\n",
      "Iter 22  time=6.25  loss=123506.48 active=514856 feature_norm=53.11\n",
      "Iter 23  time=6.28  loss=115824.87 active=496668 feature_norm=58.78\n",
      "Iter 24  time=6.21  loss=108730.17 active=494249 feature_norm=63.13\n",
      "Iter 25  time=6.27  loss=102482.32 active=476812 feature_norm=68.02\n",
      "Iter 26  time=6.27  loss=97321.98 active=460091 feature_norm=72.52\n",
      "Iter 27  time=6.22  loss=91523.09 active=429148 feature_norm=79.97\n",
      "Iter 28  time=6.28  loss=86939.67 active=417276 feature_norm=83.59\n",
      "Iter 29  time=6.27  loss=83001.68 active=395520 feature_norm=88.51\n",
      "Iter 30  time=6.42  loss=80940.29 active=374558 feature_norm=98.21\n",
      "Iter 31  time=6.58  loss=75375.05 active=378373 feature_norm=101.08\n",
      "Iter 32  time=6.23  loss=73190.23 active=371243 feature_norm=104.46\n",
      "Iter 33  time=6.22  loss=69328.71 active=349264 feature_norm=112.04\n",
      "Iter 34  time=6.22  loss=66265.91 active=336674 feature_norm=117.96\n",
      "Iter 35  time=6.26  loss=63650.64 active=328999 feature_norm=123.29\n",
      "Iter 36  time=6.28  loss=61165.45 active=316998 feature_norm=129.28\n",
      "Iter 37  time=6.22  loss=58559.55 active=291564 feature_norm=138.34\n",
      "Iter 38  time=6.21  loss=57721.63 active=273296 feature_norm=148.09\n",
      "Iter 39  time=6.23  loss=55720.84 active=274989 feature_norm=150.22\n",
      "Iter 40  time=6.20  loss=54998.89 active=271505 feature_norm=152.13\n",
      "Iter 41  time=6.25  loss=53315.84 active=258897 feature_norm=158.52\n",
      "Iter 42  time=11.95 loss=52776.56 active=244683 feature_norm=162.56\n",
      "Iter 43  time=6.20  loss=51522.21 active=242477 feature_norm=165.51\n",
      "Iter 44  time=6.25  loss=50697.34 active=238451 feature_norm=168.46\n",
      "Iter 45  time=6.21  loss=49214.82 active=221205 feature_norm=176.15\n",
      "Iter 46  time=17.73 loss=49005.57 active=219389 feature_norm=176.11\n",
      "Iter 47  time=6.21  loss=48507.95 active=216258 feature_norm=177.62\n",
      "Iter 48  time=6.21  loss=47584.82 active=207104 feature_norm=182.70\n",
      "Iter 49  time=6.19  loss=47124.68 active=198954 feature_norm=184.44\n",
      "Iter 50  time=6.20  loss=46606.75 active=192888 feature_norm=187.27\n",
      "Iter 51  time=6.39  loss=46417.74 active=185850 feature_norm=193.76\n",
      "Iter 52  time=6.58  loss=45948.87 active=187609 feature_norm=193.36\n",
      "Iter 53  time=6.21  loss=45826.22 active=185023 feature_norm=193.88\n",
      "Iter 54  time=6.23  loss=45495.44 active=175818 feature_norm=196.56\n",
      "Iter 55  time=6.18  loss=45221.59 active=170536 feature_norm=197.80\n",
      "Iter 56  time=6.20  loss=44999.22 active=167243 feature_norm=199.32\n",
      "Iter 57  time=6.26  loss=44792.19 active=164335 feature_norm=200.55\n",
      "Iter 58  time=6.24  loss=44572.85 active=158791 feature_norm=202.11\n",
      "Iter 59  time=6.20  loss=44412.97 active=155889 feature_norm=202.66\n",
      "Iter 60  time=6.19  loss=44237.07 active=152283 feature_norm=203.60\n",
      "Iter 61  time=6.24  loss=44071.75 active=149441 feature_norm=204.18\n",
      "Iter 62  time=6.22  loss=43926.22 active=147140 feature_norm=205.03\n",
      "Iter 63  time=6.21  loss=43797.09 active=145091 feature_norm=205.53\n",
      "Iter 64  time=6.22  loss=43682.61 active=142907 feature_norm=206.30\n",
      "Iter 65  time=6.24  loss=43579.18 active=140761 feature_norm=206.68\n",
      "Iter 66  time=6.20  loss=43487.44 active=139119 feature_norm=207.25\n",
      "Iter 67  time=6.19  loss=43401.29 active=137543 feature_norm=207.54\n",
      "Iter 68  time=6.22  loss=43326.94 active=135998 feature_norm=207.98\n",
      "Iter 69  time=6.22  loss=43255.82 active=134879 feature_norm=208.13\n",
      "Iter 70  time=6.20  loss=43188.25 active=133686 feature_norm=208.40\n",
      "Iter 71  time=6.33  loss=43123.92 active=132316 feature_norm=208.46\n",
      "Iter 72  time=6.50  loss=43065.90 active=131152 feature_norm=208.73\n",
      "Iter 73  time=6.26  loss=43012.37 active=130143 feature_norm=208.76\n",
      "Iter 74  time=6.23  loss=42961.77 active=129452 feature_norm=208.92\n",
      "Iter 75  time=6.23  loss=42913.90 active=128481 feature_norm=208.93\n",
      "Iter 76  time=6.21  loss=42866.56 active=127675 feature_norm=209.05\n",
      "Iter 77  time=6.24  loss=42828.36 active=126849 feature_norm=209.05\n",
      "Iter 78  time=6.21  loss=42787.96 active=126129 feature_norm=209.22\n",
      "Iter 79  time=6.18  loss=42753.18 active=125608 feature_norm=209.25\n",
      "Iter 80  time=6.19  loss=42717.66 active=125140 feature_norm=209.36\n",
      "Iter 81  time=6.20  loss=42687.60 active=124433 feature_norm=209.40\n",
      "Iter 82  time=6.16  loss=42656.71 active=123619 feature_norm=209.54\n",
      "Iter 83  time=6.22  loss=42631.12 active=123035 feature_norm=209.60\n",
      "Iter 84  time=6.24  loss=42599.11 active=122783 feature_norm=209.77\n",
      "Iter 85  time=6.29  loss=42576.31 active=122503 feature_norm=209.83\n",
      "Iter 86  time=6.21  loss=42550.77 active=122281 feature_norm=209.94\n",
      "Iter 87  time=6.30  loss=42532.13 active=121859 feature_norm=209.99\n",
      "Iter 88  time=6.24  loss=42509.33 active=121525 feature_norm=210.14\n",
      "Iter 89  time=6.25  loss=42489.26 active=121291 feature_norm=210.21\n",
      "Iter 90  time=6.23  loss=42468.15 active=121077 feature_norm=210.34\n",
      "Iter 91  time=6.22  loss=42448.53 active=120850 feature_norm=210.41\n",
      "Iter 92  time=6.21  loss=42429.87 active=120660 feature_norm=210.53\n",
      "Iter 93  time=6.32  loss=42411.29 active=120408 feature_norm=210.59\n",
      "Iter 94  time=6.25  loss=42394.34 active=120086 feature_norm=210.72\n",
      "Iter 95  time=6.22  loss=42376.45 active=119841 feature_norm=210.78\n",
      "Iter 96  time=6.22  loss=42361.75 active=119660 feature_norm=210.91\n",
      "Iter 97  time=6.23  loss=42343.09 active=119438 feature_norm=210.98\n",
      "Iter 98  time=6.20  loss=42329.09 active=119285 feature_norm=211.10\n",
      "Iter 99  time=6.21  loss=42310.91 active=119089 feature_norm=211.16\n",
      "Iter 100 time=6.21  loss=42298.36 active=118855 feature_norm=211.27\n",
      "Iter 101 time=6.20  loss=42281.24 active=118715 feature_norm=211.33\n",
      "Iter 102 time=6.21  loss=42270.78 active=118482 feature_norm=211.43\n",
      "Iter 103 time=6.22  loss=42253.45 active=118282 feature_norm=211.50\n",
      "Iter 104 time=6.22  loss=42242.78 active=118131 feature_norm=211.60\n",
      "Iter 105 time=6.22  loss=42225.70 active=117993 feature_norm=211.66\n",
      "Iter 106 time=6.22  loss=42215.45 active=117860 feature_norm=211.75\n",
      "Iter 107 time=6.20  loss=42198.92 active=117705 feature_norm=211.80\n",
      "Iter 108 time=6.16  loss=42190.07 active=117529 feature_norm=211.89\n",
      "Iter 109 time=6.23  loss=42173.61 active=117415 feature_norm=211.94\n",
      "Iter 110 time=6.19  loss=42166.22 active=117279 feature_norm=212.03\n",
      "Iter 111 time=6.18  loss=42149.33 active=117118 feature_norm=212.09\n",
      "Iter 112 time=6.20  loss=42142.28 active=116982 feature_norm=212.18\n",
      "Iter 113 time=6.19  loss=42125.76 active=116858 feature_norm=212.24\n",
      "Iter 114 time=6.20  loss=42119.06 active=116754 feature_norm=212.32\n",
      "Iter 115 time=6.20  loss=42103.78 active=116604 feature_norm=212.38\n",
      "Iter 116 time=6.18  loss=42096.58 active=116541 feature_norm=212.45\n",
      "Iter 117 time=6.21  loss=42082.26 active=116451 feature_norm=212.50\n",
      "Iter 118 time=6.18  loss=42076.62 active=116290 feature_norm=212.58\n",
      "Iter 119 time=6.21  loss=42060.93 active=116170 feature_norm=212.64\n",
      "Iter 120 time=6.21  loss=42055.31 active=116074 feature_norm=212.70\n",
      "Iter 121 time=6.20  loss=42040.36 active=116000 feature_norm=212.75\n",
      "Iter 122 time=6.20  loss=42035.84 active=115916 feature_norm=212.82\n",
      "Iter 123 time=6.29  loss=42020.71 active=115791 feature_norm=212.87\n",
      "Iter 124 time=6.24  loss=42016.15 active=115681 feature_norm=212.93\n",
      "Iter 125 time=6.23  loss=42001.27 active=115520 feature_norm=212.98\n",
      "Iter 126 time=6.20  loss=41996.50 active=115361 feature_norm=213.04\n",
      "Iter 127 time=6.22  loss=41982.02 active=115273 feature_norm=213.08\n",
      "Iter 128 time=6.20  loss=41976.86 active=115106 feature_norm=213.14\n",
      "Iter 129 time=6.84  loss=41963.14 active=115021 feature_norm=213.17\n",
      "Iter 130 time=6.73  loss=41959.60 active=114926 feature_norm=213.23\n",
      "Iter 131 time=6.55  loss=41944.66 active=114823 feature_norm=213.27\n",
      "Iter 132 time=6.38  loss=41940.55 active=114724 feature_norm=213.31\n",
      "Iter 133 time=6.54  loss=41926.18 active=114622 feature_norm=213.34\n",
      "Iter 134 time=6.69  loss=41921.28 active=114485 feature_norm=213.38\n",
      "Iter 135 time=6.52  loss=41907.65 active=114380 feature_norm=213.41\n",
      "Iter 136 time=6.32  loss=41903.33 active=114295 feature_norm=213.45\n",
      "Iter 137 time=6.21  loss=41889.68 active=114257 feature_norm=213.47\n",
      "Iter 138 time=6.26  loss=41885.69 active=114134 feature_norm=213.51\n",
      "Iter 139 time=6.26  loss=41871.15 active=114095 feature_norm=213.53\n",
      "Iter 140 time=6.26  loss=41867.26 active=114019 feature_norm=213.57\n",
      "Iter 141 time=6.27  loss=41853.00 active=113955 feature_norm=213.59\n",
      "Iter 142 time=6.27  loss=41849.09 active=113901 feature_norm=213.62\n",
      "Iter 143 time=6.28  loss=41834.36 active=113829 feature_norm=213.64\n",
      "Iter 144 time=6.55  loss=41829.33 active=113774 feature_norm=213.67\n",
      "Iter 145 time=6.86  loss=41815.37 active=113676 feature_norm=213.67\n",
      "Iter 146 time=8.05  loss=41811.05 active=113582 feature_norm=213.70\n",
      "Iter 147 time=6.75  loss=41795.71 active=113556 feature_norm=213.71\n",
      "Iter 148 time=8.10  loss=41791.41 active=113502 feature_norm=213.73\n",
      "Iter 149 time=7.20  loss=41776.95 active=113400 feature_norm=213.73\n",
      "Iter 150 time=6.75  loss=41772.46 active=113338 feature_norm=213.74\n",
      "Iter 151 time=7.21  loss=41758.54 active=113296 feature_norm=213.74\n",
      "Iter 152 time=6.96  loss=41753.97 active=113247 feature_norm=213.75\n",
      "Iter 153 time=6.54  loss=41740.67 active=113186 feature_norm=213.74\n",
      "Iter 154 time=6.69  loss=41736.62 active=113110 feature_norm=213.75\n",
      "Iter 155 time=6.61  loss=41723.09 active=113090 feature_norm=213.74\n",
      "Iter 156 time=6.75  loss=41718.78 active=113025 feature_norm=213.73\n",
      "Iter 157 time=6.76  loss=41705.78 active=112944 feature_norm=213.72\n",
      "Iter 158 time=7.20  loss=41701.73 active=112894 feature_norm=213.71\n",
      "Iter 159 time=6.78  loss=41688.58 active=112820 feature_norm=213.69\n",
      "Iter 160 time=6.59  loss=41684.99 active=112768 feature_norm=213.68\n",
      "Iter 161 time=6.66  loss=41672.10 active=112703 feature_norm=213.66\n",
      "Iter 162 time=6.67  loss=41668.75 active=112636 feature_norm=213.65\n",
      "Iter 163 time=6.84  loss=41655.86 active=112613 feature_norm=213.62\n",
      "Iter 164 time=7.04  loss=41652.08 active=112566 feature_norm=213.60\n",
      "Iter 165 time=7.16  loss=41640.12 active=112502 feature_norm=213.58\n",
      "Iter 166 time=6.57  loss=41636.53 active=112416 feature_norm=213.56\n",
      "Iter 167 time=6.63  loss=41624.71 active=112378 feature_norm=213.54\n",
      "Iter 168 time=6.97  loss=41621.37 active=112311 feature_norm=213.52\n",
      "Iter 169 time=6.75  loss=41610.04 active=112264 feature_norm=213.51\n",
      "Iter 170 time=6.63  loss=41606.99 active=112239 feature_norm=213.49\n",
      "Iter 171 time=6.50  loss=41595.47 active=112179 feature_norm=213.47\n",
      "Iter 172 time=6.79  loss=41592.16 active=112110 feature_norm=213.46\n",
      "Iter 173 time=6.49  loss=41581.54 active=112063 feature_norm=213.44\n",
      "Iter 174 time=6.51  loss=41578.29 active=111966 feature_norm=213.43\n",
      "Iter 175 time=6.52  loss=41567.73 active=111927 feature_norm=213.41\n",
      "Iter 176 time=6.50  loss=41564.92 active=111872 feature_norm=213.40\n",
      "Iter 177 time=6.43  loss=41554.56 active=111819 feature_norm=213.38\n",
      "Iter 178 time=6.49  loss=41551.80 active=111768 feature_norm=213.38\n",
      "Iter 179 time=6.47  loss=41541.39 active=111703 feature_norm=213.36\n",
      "Iter 180 time=6.34  loss=41538.33 active=111660 feature_norm=213.36\n",
      "Iter 181 time=6.36  loss=41528.71 active=111570 feature_norm=213.34\n",
      "Iter 182 time=6.48  loss=41525.49 active=111520 feature_norm=213.34\n",
      "Iter 183 time=6.48  loss=41516.25 active=111449 feature_norm=213.32\n",
      "Iter 184 time=6.47  loss=41512.66 active=111406 feature_norm=213.31\n",
      "Iter 185 time=6.47  loss=41504.00 active=111338 feature_norm=213.29\n",
      "Iter 186 time=6.47  loss=41501.07 active=111300 feature_norm=213.28\n",
      "Iter 187 time=6.44  loss=41492.25 active=111235 feature_norm=213.26\n",
      "Iter 188 time=6.36  loss=41488.63 active=111162 feature_norm=213.25\n",
      "Iter 189 time=6.35  loss=41480.63 active=111102 feature_norm=213.23\n",
      "Iter 190 time=6.76  loss=41476.76 active=111031 feature_norm=213.22\n",
      "Iter 191 time=6.97  loss=41469.31 active=110995 feature_norm=213.20\n",
      "Iter 192 time=6.73  loss=41465.28 active=110959 feature_norm=213.19\n",
      "Iter 193 time=6.63  loss=41458.44 active=110881 feature_norm=213.17\n",
      "Iter 194 time=6.60  loss=41454.38 active=110836 feature_norm=213.17\n",
      "Iter 195 time=6.70  loss=41447.69 active=110751 feature_norm=213.14\n",
      "Iter 196 time=6.71  loss=41443.23 active=110724 feature_norm=213.14\n",
      "Iter 197 time=6.73  loss=41436.83 active=110646 feature_norm=213.12\n",
      "Iter 198 time=6.81  loss=41432.64 active=110642 feature_norm=213.11\n",
      "Iter 199 time=7.86  loss=41426.80 active=110546 feature_norm=213.09\n",
      "Iter 200 time=7.63  loss=41422.06 active=110514 feature_norm=213.08\n",
      "Iter 201 time=6.80  loss=41416.46 active=110456 feature_norm=213.06\n",
      "Iter 202 time=6.87  loss=41411.67 active=110412 feature_norm=213.06\n",
      "Iter 203 time=6.75  loss=41406.46 active=110322 feature_norm=213.04\n",
      "Iter 204 time=6.73  loss=41401.62 active=110286 feature_norm=213.04\n",
      "Iter 205 time=6.38  loss=41396.71 active=110239 feature_norm=213.02\n",
      "Iter 206 time=6.52  loss=41391.63 active=110184 feature_norm=213.02\n",
      "Iter 207 time=6.57  loss=41387.13 active=110088 feature_norm=213.00\n",
      "Iter 208 time=6.83  loss=41381.91 active=110055 feature_norm=213.00\n",
      "Iter 209 time=7.44  loss=41377.46 active=110000 feature_norm=212.98\n",
      "Iter 210 time=8.32  loss=41372.44 active=109954 feature_norm=212.98\n",
      "Iter 211 time=6.61  loss=41368.27 active=109878 feature_norm=212.96\n",
      "Iter 212 time=6.71  loss=41363.33 active=109816 feature_norm=212.96\n",
      "Iter 213 time=6.36  loss=41359.27 active=109721 feature_norm=212.94\n",
      "Iter 214 time=6.25  loss=41354.24 active=109686 feature_norm=212.93\n",
      "Iter 215 time=6.26  loss=41350.32 active=109624 feature_norm=212.91\n",
      "Iter 216 time=6.25  loss=41345.51 active=109601 feature_norm=212.91\n",
      "Iter 217 time=6.23  loss=41341.53 active=109546 feature_norm=212.89\n",
      "Iter 218 time=6.27  loss=41336.64 active=109486 feature_norm=212.88\n",
      "Iter 219 time=6.23  loss=41332.85 active=109430 feature_norm=212.86\n",
      "Iter 220 time=6.20  loss=41328.23 active=109401 feature_norm=212.86\n",
      "Iter 221 time=6.25  loss=41324.49 active=109319 feature_norm=212.84\n",
      "Iter 222 time=6.25  loss=41319.82 active=109288 feature_norm=212.84\n",
      "Iter 223 time=6.25  loss=41316.12 active=109217 feature_norm=212.83\n",
      "Iter 224 time=6.24  loss=41311.54 active=109186 feature_norm=212.83\n",
      "Iter 225 time=6.42  loss=41307.89 active=109143 feature_norm=212.81\n",
      "Iter 226 time=6.23  loss=41303.52 active=109109 feature_norm=212.82\n",
      "Iter 227 time=6.23  loss=41300.00 active=109040 feature_norm=212.80\n",
      "Iter 228 time=6.22  loss=41295.79 active=109005 feature_norm=212.81\n",
      "Iter 229 time=6.23  loss=41292.35 active=108906 feature_norm=212.79\n",
      "Iter 230 time=6.29  loss=41288.14 active=108859 feature_norm=212.79\n",
      "Iter 231 time=6.50  loss=41284.86 active=108783 feature_norm=212.78\n",
      "Iter 232 time=6.44  loss=41280.77 active=108765 feature_norm=212.78\n",
      "Iter 233 time=6.42  loss=41277.58 active=108668 feature_norm=212.77\n",
      "Iter 234 time=6.53  loss=41273.48 active=108644 feature_norm=212.77\n",
      "Iter 235 time=6.76  loss=41270.28 active=108589 feature_norm=212.76\n",
      "Iter 236 time=7.00  loss=41266.27 active=108541 feature_norm=212.76\n",
      "Iter 237 time=6.77  loss=41263.16 active=108476 feature_norm=212.74\n",
      "Iter 238 time=6.62  loss=41259.17 active=108410 feature_norm=212.75\n",
      "Iter 239 time=6.88  loss=41256.23 active=108373 feature_norm=212.73\n",
      "Iter 240 time=6.53  loss=41252.19 active=108344 feature_norm=212.74\n",
      "Iter 241 time=6.59  loss=41249.34 active=108273 feature_norm=212.73\n",
      "Iter 242 time=6.58  loss=41245.19 active=108206 feature_norm=212.73\n",
      "Iter 243 time=6.57  loss=41242.49 active=108123 feature_norm=212.72\n",
      "Iter 244 time=8.11  loss=41238.25 active=108030 feature_norm=212.72\n",
      "Iter 245 time=9.21  loss=41235.31 active=107942 feature_norm=212.71\n",
      "Iter 246 time=6.92  loss=41230.92 active=107887 feature_norm=212.71\n",
      "Iter 247 time=6.78  loss=41228.48 active=107795 feature_norm=212.69\n",
      "Iter 248 time=6.61  loss=41223.93 active=107755 feature_norm=212.69\n",
      "Iter 249 time=6.51  loss=41221.66 active=107718 feature_norm=212.67\n",
      "Iter 250 time=6.45  loss=41216.75 active=107678 feature_norm=212.67\n",
      "Iter 251 time=6.44  loss=41214.51 active=107609 feature_norm=212.65\n",
      "Iter 252 time=6.50  loss=41209.66 active=107579 feature_norm=212.65\n",
      "Iter 253 time=6.89  loss=41207.51 active=107489 feature_norm=212.64\n",
      "Iter 254 time=7.46  loss=41202.80 active=107471 feature_norm=212.63\n",
      "Iter 255 time=8.12  loss=41200.85 active=107417 feature_norm=212.62\n",
      "Iter 256 time=6.90  loss=41196.20 active=107382 feature_norm=212.62\n",
      "Iter 257 time=6.53  loss=41194.31 active=107331 feature_norm=212.60\n",
      "Iter 258 time=6.66  loss=41189.60 active=107298 feature_norm=212.60\n",
      "Iter 259 time=6.51  loss=41187.91 active=107215 feature_norm=212.59\n",
      "Iter 260 time=6.52  loss=41183.11 active=107196 feature_norm=212.58\n",
      "Iter 261 time=6.49  loss=41181.59 active=107130 feature_norm=212.56\n",
      "Iter 262 time=6.49  loss=41176.58 active=107120 feature_norm=212.56\n",
      "Iter 263 time=6.54  loss=41174.90 active=107087 feature_norm=212.54\n",
      "Iter 264 time=6.50  loss=41170.18 active=107060 feature_norm=212.54\n",
      "Iter 265 time=6.47  loss=41169.03 active=107018 feature_norm=212.52\n",
      "Iter 266 time=6.49  loss=41163.76 active=107030 feature_norm=212.51\n",
      "Iter 267 time=6.49  loss=41162.72 active=106959 feature_norm=212.49\n",
      "Iter 268 time=6.50  loss=41157.54 active=106933 feature_norm=212.49\n",
      "Iter 269 time=6.48  loss=41156.54 active=106852 feature_norm=212.47\n",
      "Iter 270 time=6.49  loss=41151.39 active=106821 feature_norm=212.47\n",
      "Iter 271 time=6.49  loss=41150.38 active=106753 feature_norm=212.44\n",
      "Iter 272 time=6.88  loss=41145.46 active=106751 feature_norm=212.44\n",
      "Iter 273 time=6.75  loss=41144.58 active=106669 feature_norm=212.42\n",
      "Iter 274 time=6.55  loss=41139.56 active=106621 feature_norm=212.42\n",
      "Iter 275 time=6.78  loss=41138.46 active=106552 feature_norm=212.40\n",
      "Iter 276 time=6.70  loss=41133.63 active=106514 feature_norm=212.40\n",
      "Iter 277 time=6.95  loss=41132.72 active=106437 feature_norm=212.38\n",
      "Iter 278 time=6.97  loss=41127.69 active=106410 feature_norm=212.38\n",
      "Iter 279 time=6.95  loss=41126.84 active=106364 feature_norm=212.36\n",
      "Iter 280 time=6.60  loss=41121.87 active=106350 feature_norm=212.36\n",
      "Iter 281 time=6.26  loss=41121.20 active=106289 feature_norm=212.34\n",
      "Iter 282 time=6.45  loss=41116.04 active=106257 feature_norm=212.34\n",
      "Iter 283 time=6.55  loss=41115.20 active=106175 feature_norm=212.32\n",
      "Iter 284 time=6.48  loss=41110.32 active=106204 feature_norm=212.32\n",
      "Iter 285 time=6.28  loss=41109.55 active=106164 feature_norm=212.30\n",
      "Iter 286 time=6.57  loss=41104.69 active=106129 feature_norm=212.30\n",
      "Iter 287 time=6.78  loss=41104.27 active=106080 feature_norm=212.29\n",
      "Iter 288 time=6.71  loss=41099.14 active=106068 feature_norm=212.28\n",
      "Iter 289 time=6.53  loss=41098.78 active=106021 feature_norm=212.26\n",
      "Iter 290 time=6.51  loss=41093.65 active=105978 feature_norm=212.26\n",
      "Iter 291 time=6.45  loss=41093.13 active=105954 feature_norm=212.24\n",
      "Iter 292 time=6.43  loss=41088.08 active=105913 feature_norm=212.24\n",
      "Iter 293 time=6.54  loss=41087.87 active=105826 feature_norm=212.22\n",
      "Iter 294 time=6.60  loss=41082.73 active=105823 feature_norm=212.22\n",
      "Iter 295 time=12.95 loss=41080.00 active=105862 feature_norm=212.21\n",
      "Iter 296 time=7.25  loss=41077.44 active=105777 feature_norm=212.18\n",
      "Iter 297 time=7.23  loss=41075.85 active=105764 feature_norm=212.15\n",
      "Iter 298 time=7.46  loss=41072.20 active=105866 feature_norm=212.14\n",
      "Iter 299 time=6.61  loss=41066.58 active=105844 feature_norm=212.11\n",
      "Iter 300 time=6.39  loss=41063.59 active=105842 feature_norm=212.10\n",
      "Iter 301 time=6.58  loss=41058.88 active=105895 feature_norm=212.08\n",
      "Iter 302 time=6.55  loss=41056.61 active=105943 feature_norm=212.07\n",
      "Iter 303 time=6.90  loss=41052.58 active=105922 feature_norm=212.05\n",
      "Iter 304 time=6.49  loss=41050.71 active=105875 feature_norm=212.04\n",
      "Iter 305 time=6.51  loss=41046.82 active=105871 feature_norm=212.01\n",
      "Iter 306 time=6.40  loss=41045.82 active=105849 feature_norm=212.00\n",
      "Iter 307 time=6.54  loss=41040.65 active=105807 feature_norm=211.98\n",
      "Iter 308 time=6.93  loss=41038.72 active=105789 feature_norm=211.97\n",
      "Iter 309 time=8.73  loss=41034.40 active=105772 feature_norm=211.94\n",
      "Iter 310 time=9.17  loss=41032.44 active=105731 feature_norm=211.93\n",
      "Iter 311 time=6.66  loss=41028.60 active=105699 feature_norm=211.91\n",
      "Iter 312 time=6.71  loss=41026.74 active=105702 feature_norm=211.90\n",
      "Iter 313 time=6.67  loss=41023.43 active=105639 feature_norm=211.88\n",
      "Iter 314 time=7.01  loss=41021.65 active=105621 feature_norm=211.87\n",
      "Iter 315 time=8.57  loss=41018.02 active=105582 feature_norm=211.84\n",
      "Iter 316 time=9.87  loss=41015.98 active=105578 feature_norm=211.83\n",
      "Iter 317 time=7.11  loss=41012.72 active=105555 feature_norm=211.81\n",
      "Iter 318 time=6.67  loss=41010.54 active=105509 feature_norm=211.80\n",
      "Iter 319 time=6.92  loss=41007.49 active=105467 feature_norm=211.78\n",
      "Iter 320 time=6.97  loss=41005.32 active=105450 feature_norm=211.77\n",
      "Iter 321 time=6.62  loss=41002.39 active=105400 feature_norm=211.75\n",
      "Iter 322 time=6.37  loss=41000.32 active=105371 feature_norm=211.74\n",
      "Iter 323 time=6.48  loss=40997.24 active=105308 feature_norm=211.72\n",
      "Iter 324 time=6.54  loss=40995.21 active=105285 feature_norm=211.71\n",
      "Iter 325 time=6.82  loss=40992.01 active=105217 feature_norm=211.69\n",
      "Iter 326 time=6.97  loss=40989.97 active=105230 feature_norm=211.69\n",
      "Iter 327 time=7.25  loss=40987.03 active=105209 feature_norm=211.67\n",
      "Iter 328 time=7.17  loss=40984.91 active=105185 feature_norm=211.66\n",
      "Iter 329 time=6.83  loss=40982.12 active=105138 feature_norm=211.64\n",
      "Iter 330 time=6.62  loss=40980.03 active=105126 feature_norm=211.64\n",
      "Iter 331 time=6.52  loss=40977.41 active=105108 feature_norm=211.62\n",
      "Iter 332 time=7.12  loss=40975.22 active=105073 feature_norm=211.61\n",
      "Iter 333 time=7.14  loss=40972.86 active=105065 feature_norm=211.59\n",
      "Iter 334 time=6.72  loss=40970.56 active=105065 feature_norm=211.59\n",
      "Iter 335 time=6.45  loss=40968.38 active=105015 feature_norm=211.57\n",
      "Iter 336 time=6.64  loss=40966.12 active=104983 feature_norm=211.57\n",
      "Iter 337 time=6.68  loss=40963.97 active=104991 feature_norm=211.55\n",
      "Iter 338 time=6.42  loss=40961.70 active=104966 feature_norm=211.55\n",
      "Iter 339 time=6.61  loss=40959.77 active=104930 feature_norm=211.54\n",
      "Iter 340 time=7.24  loss=40957.30 active=104906 feature_norm=211.53\n",
      "Iter 341 time=7.93  loss=40955.50 active=104877 feature_norm=211.52\n",
      "Iter 342 time=6.84  loss=40952.97 active=104882 feature_norm=211.52\n",
      "Iter 343 time=6.59  loss=40951.31 active=104876 feature_norm=211.50\n",
      "Iter 344 time=6.76  loss=40948.82 active=104862 feature_norm=211.50\n",
      "Iter 345 time=6.71  loss=40947.21 active=104854 feature_norm=211.48\n",
      "Iter 346 time=6.57  loss=40944.66 active=104854 feature_norm=211.47\n",
      "Iter 347 time=6.57  loss=40943.16 active=104838 feature_norm=211.46\n",
      "Iter 348 time=6.99  loss=40940.66 active=104809 feature_norm=211.46\n",
      "Iter 349 time=6.64  loss=40939.30 active=104758 feature_norm=211.45\n",
      "Iter 350 time=6.49  loss=40936.58 active=104764 feature_norm=211.45\n",
      "Iter 351 time=6.58  loss=40935.35 active=104739 feature_norm=211.44\n",
      "Iter 352 time=6.53  loss=40932.59 active=104726 feature_norm=211.44\n",
      "Iter 353 time=6.66  loss=40931.41 active=104683 feature_norm=211.43\n",
      "Iter 354 time=6.58  loss=40928.68 active=104705 feature_norm=211.43\n",
      "Iter 355 time=6.53  loss=40927.55 active=104671 feature_norm=211.41\n",
      "Iter 356 time=6.73  loss=40924.97 active=104627 feature_norm=211.42\n",
      "Iter 357 time=6.91  loss=40923.74 active=104595 feature_norm=211.40\n",
      "Iter 358 time=7.60  loss=40921.12 active=104563 feature_norm=211.40\n",
      "Iter 359 time=6.48  loss=40919.92 active=104533 feature_norm=211.39\n",
      "Iter 360 time=6.53  loss=40917.24 active=104510 feature_norm=211.39\n",
      "Iter 361 time=6.56  loss=40916.07 active=104445 feature_norm=211.38\n",
      "Iter 362 time=6.57  loss=40913.48 active=104449 feature_norm=211.38\n",
      "Iter 363 time=6.48  loss=40912.32 active=104436 feature_norm=211.37\n",
      "Iter 364 time=7.14  loss=40909.80 active=104420 feature_norm=211.37\n",
      "Iter 365 time=7.16  loss=40908.65 active=104389 feature_norm=211.36\n",
      "Iter 366 time=6.52  loss=40906.08 active=104368 feature_norm=211.36\n",
      "Iter 367 time=7.09  loss=40904.95 active=104347 feature_norm=211.34\n",
      "Iter 368 time=8.79  loss=40902.37 active=104321 feature_norm=211.35\n",
      "Iter 369 time=6.84  loss=40901.27 active=104278 feature_norm=211.33\n",
      "Iter 370 time=6.58  loss=40898.79 active=104261 feature_norm=211.34\n",
      "Iter 371 time=6.58  loss=40897.72 active=104215 feature_norm=211.32\n",
      "Iter 372 time=6.56  loss=40895.32 active=104235 feature_norm=211.33\n",
      "Iter 373 time=6.68  loss=40894.22 active=104232 feature_norm=211.31\n",
      "Iter 374 time=6.87  loss=40891.85 active=104240 feature_norm=211.32\n",
      "Iter 375 time=6.71  loss=40890.80 active=104209 feature_norm=211.30\n",
      "Iter 376 time=6.39  loss=40888.51 active=104201 feature_norm=211.31\n",
      "Iter 377 time=6.65  loss=40887.36 active=104209 feature_norm=211.29\n",
      "Iter 378 time=7.68  loss=40885.20 active=104213 feature_norm=211.30\n",
      "Iter 379 time=8.98  loss=40884.09 active=104168 feature_norm=211.29\n",
      "Iter 380 time=6.65  loss=40882.05 active=104168 feature_norm=211.29\n",
      "Iter 381 time=6.95  loss=40880.86 active=104133 feature_norm=211.28\n",
      "Iter 382 time=6.68  loss=40878.93 active=104103 feature_norm=211.28\n",
      "Iter 383 time=6.76  loss=40877.74 active=104075 feature_norm=211.27\n",
      "Iter 384 time=6.68  loss=40875.78 active=104052 feature_norm=211.28\n",
      "Iter 385 time=6.45  loss=40874.58 active=104032 feature_norm=211.26\n",
      "Iter 386 time=6.44  loss=40872.74 active=104008 feature_norm=211.27\n",
      "Iter 387 time=6.51  loss=40871.49 active=103985 feature_norm=211.26\n",
      "Iter 388 time=6.94  loss=40869.72 active=103955 feature_norm=211.26\n",
      "Iter 389 time=6.51  loss=40868.37 active=103937 feature_norm=211.25\n",
      "Iter 390 time=6.62  loss=40866.74 active=103897 feature_norm=211.25\n",
      "Iter 391 time=6.62  loss=40865.35 active=103844 feature_norm=211.24\n",
      "Iter 392 time=6.57  loss=40863.83 active=103808 feature_norm=211.25\n",
      "Iter 393 time=7.41  loss=40862.38 active=103764 feature_norm=211.24\n",
      "Iter 394 time=9.06  loss=40860.99 active=103750 feature_norm=211.24\n",
      "Iter 395 time=9.41  loss=40859.55 active=103720 feature_norm=211.23\n",
      "Iter 396 time=7.33  loss=40858.23 active=103697 feature_norm=211.23\n",
      "Iter 397 time=6.66  loss=40856.69 active=103653 feature_norm=211.22\n",
      "Iter 398 time=6.65  loss=40855.44 active=103635 feature_norm=211.23\n",
      "Iter 399 time=6.65  loss=40853.96 active=103598 feature_norm=211.22\n",
      "Iter 400 time=6.23  loss=40852.83 active=103586 feature_norm=211.22\n",
      "Iter 401 time=6.75  loss=40851.25 active=103550 feature_norm=211.22\n",
      "Iter 402 time=6.63  loss=40850.18 active=103544 feature_norm=211.22\n",
      "Iter 403 time=7.61  loss=40848.53 active=103488 feature_norm=211.21\n",
      "Iter 404 time=6.64  loss=40847.50 active=103471 feature_norm=211.21\n",
      "Iter 405 time=6.99  loss=40845.83 active=103433 feature_norm=211.20\n",
      "Iter 406 time=7.19  loss=40844.80 active=103429 feature_norm=211.21\n",
      "Iter 407 time=6.64  loss=40843.14 active=103410 feature_norm=211.20\n",
      "Iter 408 time=7.32  loss=40842.21 active=103402 feature_norm=211.20\n",
      "Iter 409 time=6.51  loss=40840.50 active=103374 feature_norm=211.19\n",
      "Iter 410 time=6.44  loss=40839.69 active=103333 feature_norm=211.19\n",
      "Iter 411 time=6.47  loss=40837.82 active=103315 feature_norm=211.18\n",
      "Iter 412 time=6.55  loss=40836.98 active=103297 feature_norm=211.18\n",
      "Iter 413 time=6.50  loss=40835.18 active=103263 feature_norm=211.18\n",
      "Iter 414 time=6.21  loss=40834.41 active=103263 feature_norm=211.18\n",
      "Iter 415 time=7.18  loss=40832.63 active=103250 feature_norm=211.17\n",
      "Iter 416 time=7.53  loss=40831.94 active=103227 feature_norm=211.17\n",
      "Iter 417 time=6.57  loss=40830.12 active=103233 feature_norm=211.16\n",
      "Iter 418 time=6.70  loss=40829.46 active=103212 feature_norm=211.16\n",
      "Iter 419 time=7.18  loss=40827.60 active=103204 feature_norm=211.15\n",
      "Iter 420 time=8.50  loss=40826.90 active=103181 feature_norm=211.15\n",
      "Iter 421 time=6.96  loss=40825.12 active=103167 feature_norm=211.15\n",
      "Iter 422 time=6.57  loss=40824.51 active=103142 feature_norm=211.14\n",
      "Iter 423 time=6.46  loss=40822.71 active=103098 feature_norm=211.14\n",
      "Iter 424 time=7.58  loss=40822.29 active=103050 feature_norm=211.14\n",
      "Iter 425 time=11.02 loss=40820.20 active=103025 feature_norm=211.13\n",
      "Iter 426 time=6.75  loss=40819.82 active=102982 feature_norm=211.13\n",
      "Iter 427 time=6.35  loss=40817.75 active=102958 feature_norm=211.12\n",
      "Iter 428 time=6.33  loss=40817.37 active=102936 feature_norm=211.12\n",
      "Iter 429 time=6.82  loss=40815.38 active=102916 feature_norm=211.11\n",
      "Iter 430 time=7.54  loss=40815.08 active=102871 feature_norm=211.11\n",
      "Iter 431 time=7.05  loss=40813.06 active=102862 feature_norm=211.10\n",
      "Iter 432 time=8.63  loss=40812.83 active=102868 feature_norm=211.09\n",
      "Iter 433 time=8.90  loss=40810.69 active=102849 feature_norm=211.08\n",
      "Iter 434 time=6.40  loss=40810.41 active=102797 feature_norm=211.08\n",
      "Iter 435 time=6.31  loss=40808.39 active=102776 feature_norm=211.07\n",
      "Iter 436 time=6.28  loss=40808.18 active=102761 feature_norm=211.07\n",
      "Iter 437 time=6.29  loss=40806.16 active=102745 feature_norm=211.06\n",
      "Iter 438 time=6.69  loss=40805.91 active=102724 feature_norm=211.05\n",
      "Iter 439 time=6.53  loss=40804.02 active=102705 feature_norm=211.05\n",
      "Iter 440 time=6.58  loss=40803.88 active=102676 feature_norm=211.04\n",
      "Iter 441 time=6.68  loss=40801.91 active=102658 feature_norm=211.04\n",
      "Iter 442 time=6.49  loss=40801.65 active=102659 feature_norm=211.04\n",
      "Iter 443 time=6.56  loss=40799.83 active=102645 feature_norm=211.03\n",
      "Iter 444 time=6.33  loss=40799.64 active=102634 feature_norm=211.03\n",
      "Iter 445 time=6.51  loss=40797.74 active=102629 feature_norm=211.03\n",
      "Iter 446 time=6.63  loss=40797.67 active=102608 feature_norm=211.03\n",
      "Iter 447 time=6.57  loss=40795.70 active=102588 feature_norm=211.02\n",
      "Iter 448 time=7.02  loss=40795.66 active=102558 feature_norm=211.03\n",
      "Iter 449 time=7.04  loss=40793.62 active=102547 feature_norm=211.02\n",
      "Iter 450 time=6.79  loss=40793.50 active=102548 feature_norm=211.02\n",
      "Iter 451 time=6.65  loss=40791.63 active=102526 feature_norm=211.02\n",
      "Iter 452 time=12.72 loss=40790.55 active=102532 feature_norm=211.02\n",
      "Iter 453 time=6.54  loss=40789.43 active=102508 feature_norm=211.01\n",
      "Iter 454 time=6.51  loss=40789.28 active=102531 feature_norm=211.01\n",
      "Iter 455 time=6.49  loss=40787.41 active=102560 feature_norm=211.00\n",
      "Iter 456 time=6.50  loss=40786.27 active=102593 feature_norm=211.01\n",
      "Iter 457 time=7.05  loss=40783.68 active=102605 feature_norm=211.00\n",
      "Iter 458 time=6.49  loss=40782.48 active=102634 feature_norm=211.00\n",
      "Iter 459 time=6.32  loss=40781.11 active=102689 feature_norm=211.00\n",
      "Iter 460 time=6.29  loss=40780.06 active=102679 feature_norm=211.00\n",
      "Iter 461 time=6.33  loss=40778.76 active=102664 feature_norm=210.99\n",
      "Iter 462 time=6.39  loss=40778.02 active=102669 feature_norm=210.99\n",
      "Iter 463 time=6.56  loss=40776.58 active=102674 feature_norm=210.99\n",
      "Iter 464 time=6.32  loss=40775.77 active=102652 feature_norm=210.99\n",
      "Iter 465 time=6.65  loss=40774.12 active=102652 feature_norm=210.98\n",
      "Iter 466 time=6.75  loss=40773.35 active=102600 feature_norm=210.98\n",
      "Iter 467 time=6.73  loss=40771.73 active=102587 feature_norm=210.98\n",
      "Iter 468 time=6.84  loss=40770.97 active=102572 feature_norm=210.98\n",
      "Iter 469 time=7.20  loss=40769.69 active=102549 feature_norm=210.97\n",
      "Iter 470 time=6.43  loss=40768.98 active=102545 feature_norm=210.97\n",
      "Iter 471 time=6.56  loss=40767.59 active=102526 feature_norm=210.97\n",
      "Iter 472 time=6.57  loss=40766.97 active=102511 feature_norm=210.97\n",
      "Iter 473 time=6.50  loss=40765.49 active=102488 feature_norm=210.96\n",
      "Iter 474 time=6.53  loss=40764.95 active=102469 feature_norm=210.96\n",
      "Iter 475 time=6.44  loss=40763.37 active=102442 feature_norm=210.96\n",
      "Iter 476 time=6.24  loss=40762.91 active=102442 feature_norm=210.96\n",
      "Iter 477 time=6.22  loss=40761.38 active=102408 feature_norm=210.95\n",
      "Iter 478 time=6.83  loss=40761.04 active=102374 feature_norm=210.95\n",
      "Iter 479 time=6.60  loss=40759.39 active=102356 feature_norm=210.94\n",
      "Iter 480 time=6.25  loss=40759.06 active=102363 feature_norm=210.94\n",
      "Iter 481 time=6.28  loss=40757.45 active=102326 feature_norm=210.94\n",
      "Iter 482 time=6.21  loss=40757.18 active=102311 feature_norm=210.94\n",
      "Iter 483 time=6.25  loss=40755.47 active=102301 feature_norm=210.93\n",
      "Iter 484 time=6.63  loss=40755.25 active=102304 feature_norm=210.93\n",
      "Iter 485 time=6.54  loss=40753.56 active=102288 feature_norm=210.92\n",
      "Iter 486 time=6.53  loss=40753.40 active=102264 feature_norm=210.92\n",
      "Iter 487 time=6.46  loss=40751.66 active=102256 feature_norm=210.91\n",
      "Iter 488 time=6.57  loss=40751.50 active=102232 feature_norm=210.91\n",
      "Iter 489 time=6.63  loss=40749.84 active=102210 feature_norm=210.91\n",
      "Iter 490 time=7.29  loss=40749.69 active=102184 feature_norm=210.91\n",
      "Iter 491 time=6.73  loss=40748.03 active=102168 feature_norm=210.90\n",
      "Iter 492 time=6.50  loss=40747.92 active=102172 feature_norm=210.90\n",
      "Iter 493 time=6.47  loss=40746.21 active=102148 feature_norm=210.90\n",
      "Iter 494 time=6.47  loss=40746.13 active=102132 feature_norm=210.90\n",
      "Iter 495 time=6.54  loss=40744.39 active=102128 feature_norm=210.89\n",
      "Iter 496 time=12.47 loss=40743.42 active=102150 feature_norm=210.89\n",
      "Iter 497 time=7.06  loss=40742.32 active=102095 feature_norm=210.89\n",
      "Iter 498 time=13.85 loss=40741.05 active=102148 feature_norm=210.89\n",
      "Iter 499 time=12.97 loss=40740.24 active=102219 feature_norm=210.89\n",
      "Iter 500 time=12.61 loss=40739.28 active=102224 feature_norm=210.89\n",
      "Iter 501 time=12.53 loss=40738.19 active=102193 feature_norm=210.88\n",
      "Iter 502 time=12.64 loss=40737.20 active=102174 feature_norm=210.88\n",
      "Iter 503 time=12.55 loss=40735.94 active=102147 feature_norm=210.88\n",
      "Iter 504 time=12.42 loss=40734.97 active=102114 feature_norm=210.87\n",
      "Iter 505 time=12.57 loss=40734.05 active=102089 feature_norm=210.87\n",
      "Iter 506 time=14.94 loss=40733.06 active=102065 feature_norm=210.87\n",
      "Iter 507 time=13.54 loss=40732.09 active=102017 feature_norm=210.86\n",
      "Iter 508 time=13.12 loss=40731.15 active=101994 feature_norm=210.86\n",
      "Iter 509 time=13.38 loss=40730.11 active=101974 feature_norm=210.85\n",
      "Iter 510 time=15.46 loss=40729.20 active=101922 feature_norm=210.85\n",
      "Iter 511 time=13.57 loss=40728.11 active=101911 feature_norm=210.84\n",
      "Iter 512 time=13.60 loss=40727.27 active=101900 feature_norm=210.84\n",
      "Iter 513 time=12.65 loss=40726.20 active=101891 feature_norm=210.83\n",
      "Iter 514 time=12.05 loss=40725.40 active=101857 feature_norm=210.83\n",
      "Iter 515 time=12.13 loss=40724.35 active=101839 feature_norm=210.82\n",
      "Iter 516 time=12.05 loss=40723.56 active=101824 feature_norm=210.82\n",
      "Iter 517 time=11.99 loss=40722.52 active=101814 feature_norm=210.81\n",
      "Iter 518 time=11.97 loss=40721.76 active=101778 feature_norm=210.81\n",
      "Iter 519 time=12.24 loss=40720.69 active=101745 feature_norm=210.80\n",
      "Iter 520 time=12.06 loss=40719.96 active=101736 feature_norm=210.80\n",
      "Iter 521 time=12.01 loss=40718.92 active=101716 feature_norm=210.79\n",
      "Iter 522 time=12.11 loss=40718.23 active=101698 feature_norm=210.78\n",
      "Iter 523 time=12.54 loss=40717.22 active=101690 feature_norm=210.77\n",
      "Iter 524 time=12.08 loss=40716.53 active=101675 feature_norm=210.77\n",
      "Iter 525 time=12.00 loss=40715.55 active=101664 feature_norm=210.76\n",
      "Iter 526 time=12.35 loss=40714.89 active=101631 feature_norm=210.75\n",
      "Iter 527 time=12.53 loss=40713.91 active=101583 feature_norm=210.75\n",
      "Iter 528 time=12.10 loss=40713.26 active=101573 feature_norm=210.74\n",
      "Iter 529 time=11.98 loss=40712.32 active=101545 feature_norm=210.73\n",
      "Iter 530 time=12.05 loss=40711.72 active=101505 feature_norm=210.73\n",
      "Iter 531 time=12.96 loss=40710.73 active=101474 feature_norm=210.72\n",
      "Iter 532 time=13.21 loss=40710.14 active=101463 feature_norm=210.72\n",
      "Iter 533 time=12.15 loss=40709.20 active=101417 feature_norm=210.71\n",
      "Iter 534 time=12.52 loss=40708.65 active=101403 feature_norm=210.71\n",
      "Iter 535 time=12.45 loss=40707.72 active=101394 feature_norm=210.70\n",
      "Iter 536 time=12.37 loss=40707.19 active=101379 feature_norm=210.69\n",
      "Iter 537 time=12.68 loss=40706.27 active=101357 feature_norm=210.68\n",
      "Iter 538 time=13.07 loss=40705.73 active=101334 feature_norm=210.68\n",
      "Iter 539 time=12.90 loss=40704.87 active=101323 feature_norm=210.67\n",
      "Iter 540 time=12.55 loss=40704.32 active=101309 feature_norm=210.67\n",
      "Iter 541 time=12.87 loss=40703.49 active=101291 feature_norm=210.66\n",
      "Iter 542 time=12.88 loss=40703.01 active=101275 feature_norm=210.65\n",
      "Iter 543 time=12.63 loss=40702.15 active=101250 feature_norm=210.65\n",
      "Iter 544 time=12.86 loss=40701.67 active=101224 feature_norm=210.65\n",
      "Iter 545 time=13.58 loss=40700.79 active=101223 feature_norm=210.64\n",
      "Iter 546 time=13.72 loss=40700.29 active=101208 feature_norm=210.64\n",
      "Iter 547 time=13.07 loss=40699.45 active=101190 feature_norm=210.63\n",
      "Iter 548 time=13.19 loss=40698.94 active=101159 feature_norm=210.63\n",
      "Iter 549 time=12.82 loss=40698.12 active=101123 feature_norm=210.62\n",
      "Iter 550 time=12.28 loss=40697.66 active=101102 feature_norm=210.62\n",
      "Iter 551 time=12.48 loss=40696.78 active=101091 feature_norm=210.61\n",
      "Iter 552 time=15.17 loss=40696.32 active=101069 feature_norm=210.61\n",
      "Iter 553 time=17.61 loss=40695.47 active=101033 feature_norm=210.60\n",
      "Iter 554 time=14.26 loss=40694.97 active=101028 feature_norm=210.60\n",
      "Iter 555 time=13.77 loss=40694.18 active=101011 feature_norm=210.59\n",
      "Iter 556 time=13.91 loss=40693.74 active=101016 feature_norm=210.59\n",
      "Iter 557 time=12.98 loss=40692.93 active=101007 feature_norm=210.58\n",
      "Iter 558 time=12.81 loss=40692.52 active=101007 feature_norm=210.58\n",
      "Iter 559 time=13.10 loss=40691.72 active=100986 feature_norm=210.57\n",
      "Iter 560 time=12.48 loss=40691.32 active=100948 feature_norm=210.57\n",
      "Iter 561 time=12.75 loss=40690.51 active=100927 feature_norm=210.56\n",
      "Iter 562 time=13.26 loss=40690.05 active=100929 feature_norm=210.56\n",
      "Iter 563 time=14.33 loss=40689.32 active=100907 feature_norm=210.55\n",
      "Iter 564 time=12.99 loss=40688.96 active=100878 feature_norm=210.55\n",
      "Iter 565 time=12.52 loss=40688.14 active=100860 feature_norm=210.54\n",
      "Iter 566 time=12.87 loss=40687.76 active=100838 feature_norm=210.54\n",
      "Iter 567 time=12.95 loss=40686.99 active=100830 feature_norm=210.53\n",
      "Iter 568 time=12.82 loss=40686.62 active=100805 feature_norm=210.53\n",
      "Iter 569 time=12.75 loss=40685.86 active=100782 feature_norm=210.52\n",
      "Iter 570 time=12.98 loss=40685.39 active=100781 feature_norm=210.52\n",
      "Iter 571 time=12.49 loss=40684.74 active=100770 feature_norm=210.52\n",
      "Iter 572 time=12.02 loss=40684.36 active=100761 feature_norm=210.51\n",
      "Iter 573 time=12.06 loss=40683.62 active=100755 feature_norm=210.51\n",
      "Iter 574 time=12.03 loss=40683.25 active=100730 feature_norm=210.51\n",
      "Iter 575 time=12.48 loss=40682.55 active=100722 feature_norm=210.50\n",
      "Iter 576 time=12.93 loss=40682.21 active=100717 feature_norm=210.50\n",
      "Iter 577 time=12.53 loss=40681.51 active=100690 feature_norm=210.49\n",
      "Iter 578 time=12.81 loss=40681.11 active=100679 feature_norm=210.49\n",
      "Iter 579 time=13.11 loss=40680.48 active=100657 feature_norm=210.48\n",
      "Iter 580 time=13.04 loss=40680.15 active=100634 feature_norm=210.48\n",
      "Iter 581 time=15.28 loss=40679.47 active=100637 feature_norm=210.47\n",
      "Iter 582 time=15.31 loss=40679.12 active=100633 feature_norm=210.47\n",
      "Iter 583 time=12.79 loss=40678.49 active=100632 feature_norm=210.47\n",
      "Iter 584 time=12.58 loss=40678.12 active=100613 feature_norm=210.46\n",
      "Iter 585 time=12.74 loss=40677.50 active=100610 feature_norm=210.46\n",
      "Iter 586 time=12.71 loss=40677.12 active=100597 feature_norm=210.45\n",
      "Iter 587 time=12.72 loss=40676.49 active=100554 feature_norm=210.45\n",
      "Iter 588 time=13.00 loss=40676.16 active=100541 feature_norm=210.45\n",
      "Iter 589 time=13.02 loss=40675.50 active=100521 feature_norm=210.44\n",
      "Iter 590 time=12.72 loss=40675.19 active=100497 feature_norm=210.44\n",
      "Iter 591 time=13.38 loss=40674.52 active=100503 feature_norm=210.43\n",
      "Iter 592 time=13.25 loss=40674.16 active=100508 feature_norm=210.43\n",
      "Iter 593 time=13.06 loss=40673.55 active=100493 feature_norm=210.42\n",
      "Iter 594 time=13.23 loss=40673.23 active=100481 feature_norm=210.42\n",
      "Iter 595 time=12.66 loss=40672.59 active=100467 feature_norm=210.42\n",
      "Iter 596 time=14.14 loss=40672.29 active=100451 feature_norm=210.41\n",
      "Iter 597 time=15.29 loss=40671.67 active=100448 feature_norm=210.41\n",
      "Iter 598 time=14.66 loss=40671.39 active=100431 feature_norm=210.41\n",
      "Iter 599 time=12.78 loss=40670.76 active=100410 feature_norm=210.40\n",
      "Iter 600 time=14.65 loss=40670.42 active=100402 feature_norm=210.40\n",
      "Iter 601 time=13.95 loss=40669.87 active=100397 feature_norm=210.39\n",
      "Iter 602 time=13.08 loss=40669.61 active=100360 feature_norm=210.39\n",
      "Iter 603 time=13.91 loss=40668.99 active=100353 feature_norm=210.38\n",
      "Iter 604 time=13.78 loss=40668.71 active=100320 feature_norm=210.38\n",
      "Iter 605 time=13.28 loss=40668.13 active=100306 feature_norm=210.37\n",
      "Iter 606 time=13.13 loss=40667.88 active=100304 feature_norm=210.37\n",
      "Iter 607 time=12.76 loss=40667.27 active=100297 feature_norm=210.37\n",
      "Iter 608 time=12.73 loss=40666.97 active=100296 feature_norm=210.37\n",
      "Iter 609 time=13.43 loss=40666.45 active=100275 feature_norm=210.36\n",
      "Iter 610 time=13.21 loss=40666.21 active=100271 feature_norm=210.36\n",
      "Iter 611 time=12.66 loss=40665.62 active=100262 feature_norm=210.35\n",
      "Iter 612 time=13.88 loss=40665.36 active=100244 feature_norm=210.35\n",
      "Iter 613 time=16.26 loss=40664.82 active=100242 feature_norm=210.35\n",
      "Iter 614 time=12.89 loss=40664.59 active=100239 feature_norm=210.35\n",
      "Iter 615 time=12.10 loss=40664.02 active=100231 feature_norm=210.34\n",
      "Iter 616 time=13.20 loss=40663.74 active=100221 feature_norm=210.34\n",
      "Iter 617 time=13.05 loss=40663.25 active=100196 feature_norm=210.34\n",
      "Iter 618 time=14.00 loss=40663.03 active=100183 feature_norm=210.33\n",
      "Iter 619 time=13.80 loss=40662.49 active=100168 feature_norm=210.33\n",
      "Iter 620 time=12.93 loss=40662.26 active=100172 feature_norm=210.33\n",
      "Iter 621 time=12.63 loss=40661.73 active=100177 feature_norm=210.33\n",
      "Iter 622 time=13.81 loss=40661.50 active=100166 feature_norm=210.33\n",
      "Iter 623 time=13.27 loss=40660.99 active=100151 feature_norm=210.32\n",
      "Iter 624 time=13.25 loss=40660.75 active=100129 feature_norm=210.32\n",
      "Iter 625 time=13.13 loss=40660.27 active=100116 feature_norm=210.32\n",
      "Iter 626 time=12.68 loss=40660.06 active=100118 feature_norm=210.32\n",
      "Iter 627 time=12.44 loss=40659.55 active=100102 feature_norm=210.31\n",
      "Iter 628 time=12.51 loss=40659.34 active=100092 feature_norm=210.31\n",
      "Iter 629 time=13.66 loss=40658.83 active=100074 feature_norm=210.31\n",
      "Iter 630 time=13.59 loss=40658.59 active=100058 feature_norm=210.31\n",
      "Iter 631 time=13.43 loss=40658.12 active=100037 feature_norm=210.30\n",
      "Iter 632 time=13.63 loss=40657.92 active=100026 feature_norm=210.30\n",
      "Iter 633 time=12.75 loss=40657.43 active=100010 feature_norm=210.30\n",
      "Iter 634 time=14.32 loss=40657.22 active=99983 feature_norm=210.30\n",
      "Iter 635 time=14.30 loss=40656.73 active=99972 feature_norm=210.29\n",
      "Iter 636 time=12.71 loss=40656.54 active=99940 feature_norm=210.29\n",
      "Iter 637 time=12.49 loss=40656.03 active=99948 feature_norm=210.29\n",
      "Iter 638 time=12.55 loss=40655.79 active=99950 feature_norm=210.29\n",
      "Iter 639 time=12.47 loss=40655.34 active=99946 feature_norm=210.28\n",
      "Iter 640 time=14.47 loss=40655.15 active=99920 feature_norm=210.28\n",
      "Iter 641 time=13.17 loss=40654.65 active=99918 feature_norm=210.28\n",
      "Iter 642 time=12.52 loss=40654.45 active=99910 feature_norm=210.28\n",
      "Iter 643 time=12.52 loss=40653.98 active=99891 feature_norm=210.27\n",
      "Iter 644 time=13.41 loss=40653.80 active=99869 feature_norm=210.27\n",
      "Iter 645 time=12.91 loss=40653.32 active=99856 feature_norm=210.27\n",
      "Iter 646 time=12.68 loss=40653.08 active=99853 feature_norm=210.27\n",
      "Iter 647 time=12.62 loss=40652.68 active=99848 feature_norm=210.26\n",
      "Iter 648 time=12.45 loss=40652.49 active=99846 feature_norm=210.26\n",
      "Iter 649 time=12.52 loss=40652.02 active=99829 feature_norm=210.26\n",
      "Iter 650 time=13.25 loss=40651.81 active=99815 feature_norm=210.26\n",
      "Iter 651 time=13.17 loss=40651.37 active=99801 feature_norm=210.25\n",
      "Iter 652 time=12.24 loss=40651.20 active=99798 feature_norm=210.25\n",
      "Iter 653 time=12.56 loss=40650.73 active=99781 feature_norm=210.25\n",
      "Iter 654 time=12.39 loss=40650.50 active=99778 feature_norm=210.25\n",
      "Iter 655 time=12.52 loss=40650.11 active=99779 feature_norm=210.24\n",
      "Iter 656 time=12.59 loss=40649.91 active=99767 feature_norm=210.24\n",
      "Iter 657 time=12.68 loss=40649.47 active=99750 feature_norm=210.24\n",
      "Iter 658 time=12.63 loss=40649.27 active=99743 feature_norm=210.24\n",
      "Iter 659 time=12.51 loss=40648.84 active=99748 feature_norm=210.23\n",
      "Iter 660 time=12.22 loss=40648.65 active=99741 feature_norm=210.23\n",
      "Iter 661 time=12.45 loss=40648.21 active=99718 feature_norm=210.23\n",
      "Iter 662 time=12.83 loss=40648.02 active=99715 feature_norm=210.23\n",
      "Iter 663 time=12.85 loss=40647.60 active=99714 feature_norm=210.23\n",
      "Iter 664 time=12.73 loss=40647.45 active=99716 feature_norm=210.22\n",
      "Iter 665 time=12.44 loss=40646.99 active=99714 feature_norm=210.22\n",
      "Iter 666 time=12.49 loss=40646.82 active=99701 feature_norm=210.22\n",
      "Iter 667 time=12.63 loss=40646.38 active=99676 feature_norm=210.21\n",
      "Iter 668 time=12.88 loss=40646.22 active=99650 feature_norm=210.21\n",
      "Iter 669 time=12.56 loss=40645.79 active=99635 feature_norm=210.21\n",
      "Iter 670 time=12.76 loss=40645.63 active=99625 feature_norm=210.21\n",
      "Iter 671 time=12.90 loss=40645.21 active=99604 feature_norm=210.21\n",
      "Iter 672 time=12.68 loss=40645.07 active=99615 feature_norm=210.21\n",
      "Iter 673 time=12.72 loss=40644.63 active=99607 feature_norm=210.20\n",
      "Iter 674 time=12.73 loss=40644.49 active=99591 feature_norm=210.20\n",
      "Iter 675 time=12.75 loss=40644.07 active=99581 feature_norm=210.20\n",
      "Iter 676 time=12.38 loss=40643.90 active=99554 feature_norm=210.20\n",
      "Iter 677 time=13.01 loss=40643.50 active=99554 feature_norm=210.19\n",
      "Iter 678 time=12.99 loss=40643.38 active=99550 feature_norm=210.19\n",
      "Iter 679 time=12.74 loss=40642.93 active=99534 feature_norm=210.19\n",
      "Iter 680 time=12.56 loss=40642.80 active=99533 feature_norm=210.19\n",
      "Iter 681 time=12.56 loss=40642.37 active=99517 feature_norm=210.18\n",
      "Iter 682 time=12.86 loss=40642.21 active=99521 feature_norm=210.18\n",
      "Iter 683 time=12.66 loss=40641.81 active=99494 feature_norm=210.18\n",
      "Iter 684 time=15.01 loss=40641.67 active=99487 feature_norm=210.18\n",
      "Iter 685 time=22.00 loss=40641.25 active=99478 feature_norm=210.17\n",
      "Iter 686 time=23.55 loss=40641.14 active=99490 feature_norm=210.17\n",
      "Iter 687 time=21.21 loss=40640.71 active=99485 feature_norm=210.17\n",
      "Iter 688 time=16.90 loss=40640.60 active=99465 feature_norm=210.17\n",
      "Iter 689 time=18.33 loss=40640.17 active=99450 feature_norm=210.17\n",
      "Iter 690 time=14.37 loss=40639.98 active=99434 feature_norm=210.17\n",
      "Iter 691 time=17.67 loss=40639.64 active=99430 feature_norm=210.16\n",
      "Iter 692 time=16.78 loss=40639.51 active=99445 feature_norm=210.16\n",
      "Iter 693 time=14.47 loss=40639.09 active=99440 feature_norm=210.16\n",
      "Iter 694 time=16.88 loss=40638.95 active=99439 feature_norm=210.16\n",
      "Iter 695 time=16.40 loss=40638.55 active=99443 feature_norm=210.16\n",
      "Iter 696 time=14.54 loss=40638.41 active=99424 feature_norm=210.16\n",
      "Iter 697 time=14.68 loss=40638.02 active=99413 feature_norm=210.15\n",
      "Iter 698 time=12.78 loss=40637.85 active=99406 feature_norm=210.15\n",
      "Iter 699 time=12.11 loss=40637.54 active=99393 feature_norm=210.15\n",
      "Iter 700 time=12.76 loss=40637.40 active=99377 feature_norm=210.15\n",
      "Iter 701 time=12.84 loss=40637.01 active=99376 feature_norm=210.15\n",
      "Iter 702 time=13.15 loss=40636.88 active=99368 feature_norm=210.15\n",
      "Iter 703 time=12.80 loss=40636.49 active=99369 feature_norm=210.14\n",
      "Iter 704 time=12.55 loss=40636.34 active=99367 feature_norm=210.14\n",
      "Iter 705 time=13.17 loss=40635.97 active=99360 feature_norm=210.14\n",
      "Iter 706 time=14.61 loss=40635.82 active=99365 feature_norm=210.14\n",
      "Iter 707 time=14.32 loss=40635.47 active=99357 feature_norm=210.14\n",
      "Iter 708 time=13.97 loss=40635.34 active=99327 feature_norm=210.13\n",
      "Iter 709 time=14.05 loss=40634.94 active=99310 feature_norm=210.13\n",
      "Iter 710 time=13.77 loss=40634.82 active=99305 feature_norm=210.13\n",
      "Iter 711 time=14.72 loss=40634.42 active=99305 feature_norm=210.13\n",
      "Iter 712 time=13.76 loss=40634.29 active=99292 feature_norm=210.12\n",
      "Iter 713 time=14.29 loss=40633.92 active=99285 feature_norm=210.12\n",
      "Iter 714 time=14.64 loss=40633.81 active=99278 feature_norm=210.12\n",
      "Iter 715 time=14.76 loss=40633.42 active=99281 feature_norm=210.12\n",
      "Iter 716 time=15.30 loss=40633.33 active=99281 feature_norm=210.12\n",
      "Iter 717 time=15.05 loss=40632.92 active=99300 feature_norm=210.11\n",
      "Iter 718 time=25.83 loss=40632.80 active=99285 feature_norm=210.11\n",
      "Iter 719 time=14.53 loss=40632.43 active=99281 feature_norm=210.11\n",
      "Iter 720 time=15.91 loss=40632.32 active=99280 feature_norm=210.11\n",
      "Iter 721 time=14.32 loss=40631.94 active=99282 feature_norm=210.10\n",
      "Iter 722 time=15.76 loss=40631.83 active=99289 feature_norm=210.10\n",
      "Iter 723 time=17.45 loss=40631.47 active=99290 feature_norm=210.10\n",
      "Iter 724 time=16.49 loss=40631.38 active=99285 feature_norm=210.10\n",
      "Iter 725 time=17.62 loss=40630.99 active=99271 feature_norm=210.10\n",
      "Iter 726 time=16.57 loss=40630.88 active=99263 feature_norm=210.10\n",
      "Iter 727 time=17.45 loss=40630.52 active=99257 feature_norm=210.09\n",
      "Iter 728 time=14.52 loss=40630.42 active=99249 feature_norm=210.09\n",
      "Iter 729 time=14.73 loss=40630.05 active=99241 feature_norm=210.09\n",
      "Iter 730 time=15.03 loss=40629.92 active=99238 feature_norm=210.09\n",
      "Iter 731 time=13.89 loss=40629.59 active=99228 feature_norm=210.08\n",
      "Iter 732 time=15.21 loss=40629.48 active=99224 feature_norm=210.08\n",
      "Iter 733 time=13.60 loss=40629.11 active=99195 feature_norm=210.08\n",
      "Iter 734 time=15.74 loss=40629.01 active=99186 feature_norm=210.08\n",
      "Iter 735 time=16.19 loss=40628.64 active=99180 feature_norm=210.08\n",
      "Iter 736 time=13.26 loss=40628.55 active=99170 feature_norm=210.08\n",
      "Iter 737 time=14.24 loss=40628.18 active=99167 feature_norm=210.07\n",
      "Iter 738 time=15.02 loss=40628.05 active=99151 feature_norm=210.07\n",
      "Iter 739 time=14.90 loss=40627.73 active=99136 feature_norm=210.07\n",
      "Iter 740 time=14.01 loss=40627.64 active=99132 feature_norm=210.07\n",
      "Iter 741 time=12.87 loss=40627.26 active=99128 feature_norm=210.07\n",
      "Iter 742 time=15.00 loss=40627.16 active=99124 feature_norm=210.07\n",
      "Iter 743 time=17.20 loss=40626.80 active=99112 feature_norm=210.06\n",
      "Iter 744 time=15.02 loss=40626.71 active=99110 feature_norm=210.06\n",
      "Iter 745 time=14.23 loss=40626.35 active=99097 feature_norm=210.06\n",
      "Iter 746 time=12.14 loss=40626.20 active=99113 feature_norm=210.06\n",
      "Iter 747 time=12.17 loss=40625.91 active=99101 feature_norm=210.06\n",
      "Iter 748 time=12.44 loss=40625.81 active=99099 feature_norm=210.06\n",
      "Iter 749 time=12.30 loss=40625.45 active=99095 feature_norm=210.05\n",
      "Iter 750 time=11.98 loss=40625.33 active=99098 feature_norm=210.05\n",
      "Iter 751 time=12.59 loss=40624.99 active=99088 feature_norm=210.05\n",
      "Iter 752 time=12.41 loss=40624.87 active=99069 feature_norm=210.05\n",
      "Iter 753 time=14.90 loss=40624.53 active=99066 feature_norm=210.05\n",
      "Iter 754 time=15.11 loss=40624.40 active=99064 feature_norm=210.05\n",
      "Iter 755 time=13.85 loss=40624.11 active=99051 feature_norm=210.04\n",
      "Iter 756 time=14.20 loss=40624.00 active=99036 feature_norm=210.04\n",
      "Iter 757 time=13.93 loss=40623.68 active=99023 feature_norm=210.04\n",
      "Iter 758 time=14.49 loss=40623.55 active=99019 feature_norm=210.04\n",
      "Iter 759 time=15.64 loss=40623.24 active=99015 feature_norm=210.04\n",
      "Iter 760 time=23.38 loss=40623.12 active=98997 feature_norm=210.04\n",
      "Iter 761 time=14.87 loss=40622.81 active=98989 feature_norm=210.04\n",
      "Iter 762 time=19.41 loss=40622.69 active=98991 feature_norm=210.04\n",
      "Iter 763 time=16.05 loss=40622.39 active=98983 feature_norm=210.03\n",
      "Iter 764 time=19.86 loss=40622.28 active=98991 feature_norm=210.03\n",
      "Iter 765 time=18.93 loss=40621.97 active=98983 feature_norm=210.03\n",
      "Iter 766 time=16.83 loss=40621.86 active=98984 feature_norm=210.03\n",
      "Iter 767 time=15.19 loss=40621.56 active=98978 feature_norm=210.03\n",
      "Iter 768 time=15.90 loss=40621.45 active=98966 feature_norm=210.03\n",
      "Iter 769 time=19.45 loss=40621.14 active=98952 feature_norm=210.03\n",
      "Iter 770 time=21.14 loss=40621.03 active=98957 feature_norm=210.03\n",
      "Iter 771 time=16.57 loss=40620.74 active=98965 feature_norm=210.02\n",
      "Iter 772 time=18.79 loss=40620.64 active=98963 feature_norm=210.02\n",
      "Iter 773 time=16.75 loss=40620.33 active=98959 feature_norm=210.02\n",
      "Iter 774 time=13.46 loss=40620.23 active=98951 feature_norm=210.02\n",
      "Iter 775 time=12.80 loss=40619.93 active=98937 feature_norm=210.02\n",
      "Iter 776 time=12.49 loss=40619.83 active=98923 feature_norm=210.02\n",
      "Iter 777 time=12.65 loss=40619.54 active=98917 feature_norm=210.01\n",
      "Iter 778 time=12.62 loss=40619.45 active=98918 feature_norm=210.01\n",
      "Iter 779 time=12.50 loss=40619.15 active=98896 feature_norm=210.01\n",
      "Iter 780 time=12.51 loss=40619.07 active=98901 feature_norm=210.01\n",
      "Iter 781 time=12.45 loss=40618.75 active=98894 feature_norm=210.01\n",
      "Iter 782 time=12.68 loss=40618.67 active=98887 feature_norm=210.01\n",
      "Iter 783 time=12.05 loss=40618.36 active=98881 feature_norm=210.01\n",
      "Iter 784 time=12.00 loss=40618.28 active=98874 feature_norm=210.01\n",
      "Iter 785 time=12.47 loss=40617.97 active=98871 feature_norm=210.01\n",
      "Iter 786 time=15.06 loss=40617.90 active=98865 feature_norm=210.01\n",
      "Iter 787 time=14.08 loss=40617.58 active=98854 feature_norm=210.00\n",
      "Iter 788 time=12.93 loss=40617.50 active=98855 feature_norm=210.00\n",
      "Iter 789 time=12.50 loss=40617.19 active=98868 feature_norm=210.00\n",
      "Iter 790 time=12.75 loss=40617.12 active=98868 feature_norm=210.00\n",
      "Iter 791 time=12.97 loss=40616.81 active=98867 feature_norm=210.00\n",
      "Iter 792 time=14.68 loss=40616.73 active=98860 feature_norm=210.00\n",
      "Iter 793 time=14.30 loss=40616.42 active=98844 feature_norm=210.00\n",
      "Iter 794 time=13.23 loss=40616.36 active=98841 feature_norm=210.00\n",
      "Iter 795 time=12.77 loss=40616.03 active=98839 feature_norm=210.00\n",
      "Iter 796 time=12.35 loss=40615.95 active=98831 feature_norm=210.00\n",
      "Iter 797 time=12.67 loss=40615.65 active=98827 feature_norm=210.00\n",
      "Iter 798 time=12.94 loss=40615.59 active=98823 feature_norm=210.00\n",
      "Iter 799 time=12.95 loss=40615.26 active=98824 feature_norm=210.00\n",
      "Iter 800 time=12.18 loss=40615.17 active=98815 feature_norm=210.00\n",
      "Iter 801 time=11.98 loss=40614.87 active=98814 feature_norm=210.00\n",
      "Iter 802 time=11.96 loss=40614.81 active=98814 feature_norm=210.00\n",
      "Iter 803 time=12.02 loss=40614.48 active=98813 feature_norm=209.99\n",
      "Iter 804 time=12.02 loss=40614.37 active=98806 feature_norm=209.99\n",
      "Iter 805 time=12.14 loss=40614.10 active=98806 feature_norm=209.99\n",
      "Iter 806 time=12.45 loss=40614.02 active=98818 feature_norm=209.99\n",
      "Iter 807 time=12.24 loss=40613.70 active=98814 feature_norm=209.99\n",
      "Iter 808 time=11.99 loss=40613.62 active=98824 feature_norm=209.99\n",
      "Iter 809 time=12.30 loss=40613.32 active=98808 feature_norm=209.99\n",
      "Iter 810 time=15.33 loss=40613.25 active=98802 feature_norm=209.99\n",
      "Iter 811 time=13.43 loss=40612.94 active=98791 feature_norm=209.99\n",
      "Iter 812 time=12.16 loss=40612.84 active=98784 feature_norm=209.99\n",
      "Iter 813 time=12.10 loss=40612.58 active=98777 feature_norm=209.99\n",
      "Iter 814 time=12.05 loss=40612.51 active=98777 feature_norm=209.99\n",
      "Iter 815 time=12.10 loss=40612.19 active=98774 feature_norm=209.99\n",
      "Iter 816 time=13.71 loss=40612.13 active=98767 feature_norm=209.99\n",
      "Iter 817 time=12.15 loss=40611.81 active=98776 feature_norm=209.98\n",
      "Iter 818 time=12.09 loss=40611.74 active=98765 feature_norm=209.98\n",
      "Iter 819 time=12.07 loss=40611.43 active=98762 feature_norm=209.98\n",
      "Iter 820 time=12.03 loss=40611.31 active=98757 feature_norm=209.98\n",
      "Iter 821 time=12.26 loss=40611.07 active=98743 feature_norm=209.98\n",
      "Iter 822 time=13.39 loss=40610.98 active=98738 feature_norm=209.98\n",
      "Iter 823 time=16.50 loss=40610.68 active=98731 feature_norm=209.98\n",
      "Iter 824 time=16.44 loss=40610.60 active=98741 feature_norm=209.98\n",
      "Iter 825 time=17.33 loss=40610.29 active=98719 feature_norm=209.98\n",
      "Iter 826 time=15.53 loss=40610.20 active=98717 feature_norm=209.98\n",
      "Iter 827 time=15.44 loss=40609.91 active=98718 feature_norm=209.97\n",
      "Iter 828 time=14.49 loss=40609.82 active=98726 feature_norm=209.98\n",
      "Iter 829 time=13.04 loss=40609.57 active=98728 feature_norm=209.97\n",
      "Iter 830 time=13.33 loss=40609.49 active=98721 feature_norm=209.97\n",
      "Iter 831 time=13.61 loss=40609.20 active=98714 feature_norm=209.97\n",
      "Iter 832 time=13.39 loss=40609.14 active=98726 feature_norm=209.97\n",
      "Iter 833 time=13.60 loss=40608.85 active=98734 feature_norm=209.97\n",
      "Iter 834 time=16.07 loss=40608.79 active=98727 feature_norm=209.97\n",
      "Iter 835 time=14.48 loss=40608.50 active=98720 feature_norm=209.97\n",
      "Iter 836 time=13.06 loss=40608.43 active=98719 feature_norm=209.97\n",
      "Iter 837 time=13.11 loss=40608.15 active=98710 feature_norm=209.97\n",
      "Iter 838 time=13.10 loss=40608.10 active=98699 feature_norm=209.97\n",
      "Iter 839 time=13.51 loss=40607.80 active=98687 feature_norm=209.96\n",
      "Iter 840 time=14.01 loss=40607.75 active=98676 feature_norm=209.96\n",
      "Iter 841 time=12.77 loss=40607.45 active=98662 feature_norm=209.96\n",
      "Iter 842 time=12.53 loss=40607.40 active=98662 feature_norm=209.96\n",
      "Iter 843 time=12.16 loss=40607.10 active=98651 feature_norm=209.96\n",
      "Iter 844 time=12.11 loss=40607.02 active=98652 feature_norm=209.96\n",
      "Iter 845 time=12.61 loss=40606.76 active=98646 feature_norm=209.96\n",
      "Iter 846 time=12.51 loss=40606.70 active=98651 feature_norm=209.96\n",
      "Iter 847 time=12.72 loss=40606.39 active=98648 feature_norm=209.96\n",
      "Iter 848 time=14.10 loss=40606.35 active=98634 feature_norm=209.96\n",
      "Iter 849 time=12.80 loss=40606.04 active=98636 feature_norm=209.96\n",
      "Iter 850 time=14.46 loss=40605.99 active=98633 feature_norm=209.96\n",
      "Iter 851 time=13.18 loss=40605.70 active=98635 feature_norm=209.96\n",
      "Iter 852 time=13.83 loss=40605.67 active=98646 feature_norm=209.96\n",
      "Iter 853 time=14.88 loss=40605.37 active=98650 feature_norm=209.95\n",
      "Iter 854 time=24.14 loss=40605.34 active=98643 feature_norm=209.95\n",
      "Iter 855 time=15.04 loss=40605.03 active=98634 feature_norm=209.95\n",
      "Iter 856 time=13.59 loss=40605.00 active=98632 feature_norm=209.95\n",
      "Iter 857 time=15.87 loss=40604.70 active=98624 feature_norm=209.95\n",
      "Iter 858 time=14.35 loss=40604.61 active=98617 feature_norm=209.95\n",
      "Iter 859 time=12.68 loss=40604.37 active=98613 feature_norm=209.95\n",
      "Iter 860 time=12.31 loss=40604.30 active=98618 feature_norm=209.95\n",
      "Iter 861 time=12.43 loss=40604.02 active=98619 feature_norm=209.95\n",
      "Iter 862 time=12.28 loss=40603.94 active=98615 feature_norm=209.95\n",
      "Iter 863 time=12.89 loss=40603.68 active=98593 feature_norm=209.94\n",
      "Iter 864 time=12.55 loss=40603.58 active=98592 feature_norm=209.94\n",
      "Iter 865 time=12.22 loss=40603.34 active=98588 feature_norm=209.94\n",
      "Iter 866 time=12.27 loss=40603.24 active=98592 feature_norm=209.94\n",
      "Iter 867 time=12.19 loss=40603.02 active=98588 feature_norm=209.94\n",
      "Iter 868 time=12.22 loss=40602.93 active=98581 feature_norm=209.94\n",
      "Iter 869 time=12.25 loss=40602.69 active=98564 feature_norm=209.94\n",
      "Iter 870 time=12.37 loss=40602.60 active=98559 feature_norm=209.94\n",
      "Iter 871 time=12.51 loss=40602.36 active=98555 feature_norm=209.94\n",
      "Iter 872 time=12.24 loss=40602.28 active=98554 feature_norm=209.94\n",
      "Iter 873 time=12.23 loss=40602.04 active=98549 feature_norm=209.94\n",
      "Iter 874 time=12.29 loss=40601.95 active=98528 feature_norm=209.94\n",
      "Iter 875 time=12.23 loss=40601.72 active=98530 feature_norm=209.93\n",
      "Iter 876 time=12.35 loss=40601.65 active=98525 feature_norm=209.93\n",
      "Iter 877 time=12.17 loss=40601.39 active=98523 feature_norm=209.93\n",
      "Iter 878 time=12.45 loss=40601.34 active=98516 feature_norm=209.93\n",
      "Iter 879 time=12.47 loss=40601.07 active=98512 feature_norm=209.93\n",
      "Iter 880 time=12.23 loss=40601.02 active=98496 feature_norm=209.93\n",
      "Iter 881 time=12.21 loss=40600.75 active=98498 feature_norm=209.93\n",
      "Iter 882 time=12.34 loss=40600.70 active=98490 feature_norm=209.93\n",
      "Iter 883 time=12.27 loss=40600.44 active=98475 feature_norm=209.93\n",
      "Iter 884 time=12.22 loss=40600.40 active=98477 feature_norm=209.93\n",
      "Iter 885 time=12.80 loss=40600.13 active=98471 feature_norm=209.93\n",
      "Iter 886 time=14.98 loss=40600.09 active=98473 feature_norm=209.93\n",
      "Iter 887 time=12.86 loss=40599.82 active=98481 feature_norm=209.93\n",
      "Iter 888 time=12.60 loss=40599.76 active=98475 feature_norm=209.93\n",
      "Iter 889 time=12.52 loss=40599.51 active=98463 feature_norm=209.92\n",
      "Iter 890 time=13.17 loss=40599.46 active=98462 feature_norm=209.92\n",
      "Iter 891 time=12.84 loss=40599.20 active=98466 feature_norm=209.92\n",
      "Iter 892 time=12.98 loss=40599.15 active=98457 feature_norm=209.92\n",
      "Iter 893 time=12.71 loss=40598.89 active=98450 feature_norm=209.92\n",
      "Iter 894 time=12.55 loss=40598.84 active=98443 feature_norm=209.92\n",
      "Iter 895 time=13.13 loss=40598.58 active=98444 feature_norm=209.92\n",
      "Iter 896 time=13.65 loss=40598.53 active=98446 feature_norm=209.92\n",
      "Iter 897 time=13.05 loss=40598.28 active=98451 feature_norm=209.92\n",
      "Iter 898 time=15.45 loss=40598.23 active=98448 feature_norm=209.92\n",
      "Iter 899 time=14.50 loss=40597.97 active=98437 feature_norm=209.91\n",
      "Iter 900 time=13.43 loss=40597.93 active=98437 feature_norm=209.91\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 8876.788\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 98437 (9810624)\n",
      "Number of active attributes: 44937 (265115)\n",
      "Number of active labels: 37 (37)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.587\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=True, all_possible_transitions=True,\n",
       "    c1=0.3584489507233674, c2=0.11652449959538214, keep_tempfiles=None,\n",
       "    max_iterations=900, verbose=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training CRF model with best parameters from random search\n",
    "crf3 = CRF(algorithm='lbfgs', \n",
    "           max_iterations=900, \n",
    "           verbose=True, \n",
    "           c1=0.3584489507233674, \n",
    "           c2=0.11652449959538214, \n",
    "           all_possible_states=True,\n",
    "           all_possible_transitions=True)\n",
    "crf3.fit(train_dicts, train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1:0.9692182046792559\n",
      "Macro F1:0.7218686604128397\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   B-CARDINAL      0.837     0.882     0.859      1216\n",
      "       B-DATE      0.886     0.890     0.888      2230\n",
      "      B-EVENT      0.744     0.492     0.593       130\n",
      "        B-FAC      0.516     0.322     0.397       149\n",
      "        B-GPE      0.924     0.944     0.934      2738\n",
      "   B-LANGUAGE      0.944     0.588     0.724       114\n",
      "        B-LAW      0.515     0.362     0.425        47\n",
      "        B-LOC      0.776     0.688     0.729       231\n",
      "      B-MONEY      0.936     0.923     0.929       712\n",
      "       B-NORP      0.897     0.918     0.907       928\n",
      "    B-ORDINAL      0.794     0.883     0.836       222\n",
      "        B-ORG      0.868     0.827     0.847      3024\n",
      "    B-PERCENT      0.930     0.920     0.925       574\n",
      "     B-PERSON      0.882     0.900     0.891      2082\n",
      "    B-PRODUCT      0.463     0.307     0.369       101\n",
      "   B-QUANTITY      0.894     0.672     0.767       125\n",
      "       B-TIME      0.705     0.576     0.634       203\n",
      "B-WORK_OF_ART      0.467     0.418     0.441        67\n",
      "   I-CARDINAL      0.849     0.778     0.812       428\n",
      "       I-DATE      0.892     0.899     0.895      2615\n",
      "      I-EVENT      0.709     0.547     0.618       307\n",
      "        I-FAC      0.593     0.425     0.495       254\n",
      "        I-GPE      0.848     0.856     0.852       689\n",
      "   I-LANGUAGE      0.000     0.000     0.000         9\n",
      "        I-LAW      0.497     0.471     0.484       157\n",
      "        I-LOC      0.739     0.725     0.732       222\n",
      "      I-MONEY      0.964     0.962     0.963      1464\n",
      "       I-NORP      0.881     0.698     0.779        53\n",
      "        I-ORG      0.869     0.893     0.881      4146\n",
      "    I-PERCENT      0.951     0.946     0.949       801\n",
      "     I-PERSON      0.869     0.934     0.900      1430\n",
      "    I-PRODUCT      0.504     0.648     0.567        91\n",
      "   I-QUANTITY      0.874     0.736     0.799       216\n",
      "       I-TIME      0.722     0.692     0.707       263\n",
      "I-WORK_OF_ART      0.475     0.467     0.471       165\n",
      "            O      0.989     0.990     0.989    141995\n",
      "\n",
      "     accuracy                          0.969    170198\n",
      "    macro avg      0.756     0.699     0.722    170198\n",
      " weighted avg      0.969     0.969     0.969    170198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf3.predict(dev_dicts)\n",
    "print(f\"Micro F1:{flat_f1_score(dev_tags, y_pred, average='micro')}\")\n",
    "print(f\"Macro F1:{flat_f1_score(dev_tags, y_pred, average='macro')}\")\n",
    "print(f\"{flat_classification_report(dev_tags, y_pred, digits=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 transitions: [(('I-MONEY', 'I-MONEY'), 11.153637), (('I-LAW', 'I-LAW'), 10.41666), (('I-EVENT', 'I-EVENT'), 10.382468), (('I-LOC', 'I-LOC'), 10.356205), (('B-TIME', 'I-TIME'), 10.105098), (('I-FAC', 'I-FAC'), 10.019691), (('I-TIME', 'I-TIME'), 9.916139), (('I-GPE', 'I-GPE'), 9.833531), (('I-QUANTITY', 'I-QUANTITY'), 9.638192), (('I-CARDINAL', 'I-CARDINAL'), 9.549802)]\n",
      "\n",
      "Bottom 10 transitions: [(('O', 'I-EVENT'), -5.593083), (('O', 'I-FAC'), -5.797168), (('O', 'I-MONEY'), -5.865978), (('O', 'I-LOC'), -5.916598), (('O', 'I-GPE'), -6.105288), (('O', 'I-PERSON'), -6.139959), (('O', 'I-WORK_OF_ART'), -6.240348), (('O', 'I-CARDINAL'), -6.426434), (('O', 'I-DATE'), -7.908284), (('O', 'I-ORG'), -9.424757)]\n"
     ]
    }
   ],
   "source": [
    "# Printing top 10 and bottom 10 transitions to evaluate model empirically\n",
    "\n",
    "transition_feats = crf3.transition_features_\n",
    "# top 10\n",
    "top_10 = sorted(transition_feats.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "# bottom 10\n",
    "bottom_10 = sorted(transition_feats.items(), key=lambda x: x[1], reverse=True)[-10:]\n",
    "print(f\"Top 10 transitions: {top_10}\")\n",
    "print()\n",
    "print(f\"Bottom 10 transitions: {bottom_10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The observed transitions appear to make sense because they are representing logical transitions between entities. For example, `('B-TIME', 'I-TIME')` may represent time in HH:MM format, just as `('B-DATE', 'I-DATE')` may represent a date in MM/DD format.\n",
    ">\n",
    "> Conversely, transitions that don't seem to make sense are ranked lower such as those starting with `O` and following with an `I`tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on Test Set and Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = [ontonotes_path + 'test_untagged/' + file for file in os.listdir(ontonotes_path + 'test_untagged/')]\n",
    "test_data = sorted(test_data) # ensures the files are in a standard order for consistency\n",
    "test_dicts = []\n",
    "# creates feature dicts\n",
    "for file in test_data:\n",
    "    with open(file, encoding=\"utf-8\") as f:\n",
    "        for sentence in f:\n",
    "            curr_tokens = sentence.split()\n",
    "            test_dicts.append(sentence2features(curr_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# makes predictions and saves them in csv file\n",
    "header = ['Id', 'Predicted']\n",
    "y_pred = crf3.predict(test_dicts)\n",
    "i = 0\n",
    "with open(\"test_tags.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(header) \n",
    "    for pred in y_pred:\n",
    "        for tag in pred:\n",
    "            writer.writerow([i, tag])\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After iterating several times over the training procedure, I reached a `micro f1` score of `0.96838` on the public leaderboard (calculated on approx. 50% of the test data) and `0.96819` on the private leaderboard (calculated on the remaining 50% of test data), reaching 2nd and 1st place respectively. See the [competition's Leaderboard](https://www.kaggle.com/c/colx-563-lab-assignment-1/leaderboard) for the final standings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
